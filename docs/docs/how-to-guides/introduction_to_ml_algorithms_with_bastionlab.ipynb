{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"colab_button\">\n",
    "  <h1>Introduction to Machine Learning Algorithms with BastionLab</h1>\n",
    "  <a target=\"_blank\" href=\"https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.7/docs/docs/how-to-guides/introduction_to_ml_algorithms_with_bastionlab.ipynb\"> \n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "</div>\n",
    "______________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is a subfield of artificial intelligence that focuses on the development of algorithms that can make predictions or decisions based on data. ML allows us to harness the growing quantity of data around us to create smart and powerful AI applications, such as improving the accuracy of the diagnosis of illnesses or detecting cyber attacks.\n",
    "\n",
    "Working with machine learning algorithms is a key part of BastionLab's offer, allowing users to train and deploy models using popular machine learning algorithms. What sets BastionLab apart from other softwares that facilitate ML training and deployment is its unique privacy features, allowing data owners to keep their datasets safe throughout the ML pipeline.\n",
    "\n",
    "In this Jupyter notebook, we will explore four popular machine learning algorithms, their applications, and how to implement them using BastionLab.\n",
    "\n",
    "The four algorithms we will cover are:\n",
    "\n",
    "1. Linear Regression - for predicting continuous values\n",
    "2. Gaussian Naive Bayes - for classification problems with continuous features\n",
    "3. Logistic Regression - for binary and multi-class classification problems\n",
    "4. Decision Trees - for classification and regression problems\n",
    "\n",
    "We will be using various datasets to illustrate the applications of these algorithms.\n",
    "\n",
    "So without further ado, let's start exploring these machine learning algorithms!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "----------\n",
    "1. [Pre-requisites](#pre-requisites)\n",
    "2. [Setting up and connecting to server](#Setting-up-and-connecting-to-server)\n",
    "3. [Linear Regression](#linear-regression)\n",
    "4. [Gaussian Naive Bayes](#gaussian-naive-bayes)\n",
    "5. [Logistic Regression](#logistic-regression)\n",
    "    - [Binomial Logistic Regression](#binomial-logistic-regression)\n",
    "    - [Multinomial Logistic Regression](#multinomial-logistic-regression)\n",
    "6. [Decision Trees](#decision-trees)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "________________________________________________\n",
    "### Installation\n",
    "\n",
    "In order to run this notebook, we need to:\n",
    "- Have [Python3.7](https://www.python.org/downloads/) (or greater) and [Python Pip](https://pypi.org/project/pip/) installed\n",
    "- Install [BastionLab](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/)\n",
    "- Install [Numpy](https://pypi.org/project/numpy)\n",
    "- Install [scikit-learn](https://pypi.org/project/scikit-learn)\n",
    "\n",
    "We can install the latter three packages by running the code block below. \n",
    "\n",
    ">You can see our [Installation page](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/) to find the installation method that best suits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bastionlab\n",
    "!pip install bastionlab_server\n",
    "!pip install numpy\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up and connecting to server\n",
    "---------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching the server\n",
    "\n",
    "First things first: we need to launch the BastionLab server. \n",
    "\n",
    "In production we recommend this is done using our Docker image, but for testing purposes you can use our `bastionlab_server` package, which removes the need for user authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch bastionlab_server test package\n",
    "import bastionlab_server\n",
    "\n",
    "srv = bastionlab_server.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*For more details on how you can set up the server using our Docker image, check out our [Installation Tutorial](../getting-started/installation.md).*\n",
    "\n",
    "### Connecting to the server\n",
    "Next, we will connect to the server using the following snipped of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bastionlab import Connection\n",
    "\n",
    "# connect to server instance\n",
    "connection = Connection(\"localhost\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition warning\">\n",
    "    Please note that the above connection created is an insecure connection. You can refer to the <a href=\"https://github.com/mithril-security/bastionlab/blob/master/docs/docs/tutorials/authentication.ipynb\">Authentication tutorial</a> to learn about setting up secure connections to the BastionLab server.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bastionlab.polars.policy import Policy, TrueRule, Log\n",
    "\n",
    "policy = Policy(safe_zone=TrueRule(), unsafe_handling=Log(), savable=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To keep this overview short and simple, we will use weak but reasonable guarantees. If you're interested in setting up stricter policies, you are encouraged to have a look at our [Privacy policy tutorial](https://github.com/mithril-security/bastionlab/blob/master/docs/docs/tutorials/policy.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "------------------------------------------------------------------\n",
    "\n",
    "### Overview\n",
    "Linear Regression is a supervised learning algorithm used for predicting a continuous outcome variable (also known as the response variable) based on one or more predictor variables. In other words, it is a technique for modeling the relationship between a dependent variable (Y) and one or more independent variables (X).\n",
    "\n",
    "The goal of Linear Regression is to find the best-fit line or hyperplane that describes the relationship between the independent and dependent variables. This line or hyperplane is defined by a set of coefficients that determine the slope and intercept of the line or hyperplane."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications\n",
    "\n",
    "Linear Regression is widely used across various fields such as finance, economics, healthcare, and social sciences. Some of its applications include:\n",
    "\n",
    "* Predicting stock prices\n",
    "* Forecasting sales revenue\n",
    "* Estimating the impact of a marketing campaign on sales\n",
    "* Predicting the price of a house based on its features such as size, location, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walk-through\n",
    "\n",
    "Let's now use Linear Regression in BastionLab to predict housing prices.\n",
    "\n",
    "\n",
    "**Step 1: Importing Libraries**\n",
    "\n",
    "The first step is to import the required libraries. We will be using NumPy and Polars for data manipulation, the BastionLab Linfa Models submodule for building the Linear Regression model and the BastionLab Linfa Metrics submodule for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from bastionlab.linfa.models import LinearRegression\n",
    "from bastionlab.linfa.metrics import mean_squared_error\n",
    "from bastionlab.polars import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Loading Data**\n",
    "\n",
    "The scikit-learn dependency we previous downloaded contains built-in datasets that we can load using the sklearn datasets submodule. We will load up the California Housing dataset, a popular dataset used in machine learning and statistics. It contains data collected in the 1990 California public census including information on housing prices, demographics, and geography for each block group in California. The dataset contains 20,640 observations and 8 attributes, including the median house value, median income and housing occupancy rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "# load dataset from sklearn\n",
    "data = datasets.fetch_california_housing(as_frame=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fetch_california_housing` function returns a dictionary-like object with both the feature matrix `X` (the input data) and target vector `Y` (the output data/labels), as well as some additional metadata about the dataset. We set the option `as_frame` to True to get our data as Pandas objects. \n",
    "\n",
    "In order to send this data to BastionLab, we need the feature matrix and target data as Polars DataFrames. We can convert the data to Polars DataFrames by supplying the Polars DataFrame constructor method with our Pandas objects. Our features matrix is a Pandas DataFrame and will be converted to a Polars DataFrame without any further intervention. Our target vector however is a Pandas Series, which is not accepted by the Polars DataFrame constructor. We must therefore first use Pandas `to_numpy()` method to convert the Series into a numpy array.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inputs from Pandas DataFrame into Polars DataFrame\n",
    "inputs = pl.DataFrame(data[\"data\"])\n",
    "\n",
    "# Convert target into Polars DataFrame from Numpy Ndarray\n",
    "target = pl.DataFrame(data[\"target\"].to_numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to send our data to BastionLab. We do this by using BastionLab's `send_df` method and supplying it with our inputs and targets Polars dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload our inputs and target data\n",
    "remote_inputs = connection.client.polars.send_df(inputs)\n",
    "remote_target = connection.client.polars.send_df(target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The server returns a `FetchableLazyFrame` for both the inputs and target dataframes. This is a reference to the remote DataFrames which can be used as if it were locally available."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Data Preparation**\n",
    "\n",
    "Before building the model, we need to clean and prepare the data. \n",
    "\n",
    "The data cleaning and preparation involved will dependent on the dataset in question but can involve splitting the data into training and testing sets, scaling the data, and handling missing values.\n",
    "\n",
    "We will start by converting out remote datasets into remote arrays using BastionLab's `to_array` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_X = remote_inputs.to_array()\n",
    "remote_Y = remote_target.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition important\">\n",
    "    To learn more about this method, checkout our <a href=\"#\">data conversion tutorial</a>\n",
    "</div>\n",
    "\n",
    "Now that we have converted our remote dataframes into remote arrays, we can split our data into training and testing sets using BastionLab's `train_test_split` method, which is similar to sklearn's method of the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing sets in BastionLab\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    remote_X,\n",
    "    remote_Y,\n",
    "    test_size=0.3,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the `test_size` to 0.3, we allocate 30% of our datasets for validation to check our model fits our data correctly.\n",
    "\n",
    "By setting `shuffle` to True, we split the data randomly. The shuffle parameter is needed to prevent non-random assignment to to train and test sets.\n",
    "\n",
    "The `train_test_split` method returns our training and testing X and Y data (input and target data) as remote arrays."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Training and testing the Model**\n",
    "\n",
    "We can now build and run the Linear Regression model in BastionLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Training the model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the target values for the test set\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `LinearRegression()` constructor to get an instance of the linear regression model.\n",
    "\n",
    "We then use the `fit` method with our training datasets to train the model.\n",
    "\n",
    "Finally, we use the `predict` method to predict the target values for out test input data. Target values are returned to us as a FetchableLazyFrame."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Model Evaluation**\n",
    "\n",
    "We can evaluate our model using various different metrics, with the following methods available in BastionLab: SimpleValidationRequest, R2Score, MeanAbsoluteError, MeanSquaredError, MeanSquaredLogError, MedianAbsoluteError, MaxError, ExplainedVariance, Accuracy, F1Score, Mcc, ClassificationMetric and RegressionMetric.\n",
    "\n",
    "In this example, we will use the Mean Squared Error (MSE) metric to evaluate our data. MSE is one of the the most popular evaluation metrics for linear regression models.\n",
    "\n",
    "To evaluate our test data using MSE, we use BastionLab's `mean_squared_error`, supplying it with the original target data and the values predicted by our model. We need to convert our `y_pred` `FetchableLazyFrame` into an numpy ndarray for this to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchableLazyFrame(identifier=e94f6468-2263-41ea-be60-9d57eef12ee3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred.to_array())\n",
    "mse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function returns our MSE score as a `FetchableLazyFrame`. To view the results, we need to run `fetch` on this FetchableLazyFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 1)\n",
      "┌────────────────────┐\n",
      "│ mean_squared_error │\n",
      "│ ---                │\n",
      "│ f64                │\n",
      "╞════════════════════╡\n",
      "│ 0.539386           │\n",
      "└────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "mse.fetch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a MSE score of around 0.5. With MSE scores, the closer to 0 the better the model. A perfect model would return an MSE of 0."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We have seen how to upload training and testing data to BastionLab, prepare the data and use it to train and evaluate a Linear Regression model.\n",
    "\n",
    "Let's now move onto the next ML algorithm we are going to explore today, Gaussian Naive Bayes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### Overview\n",
    "\n",
    "Gaussian Naive Bayes is a probabilistic algorithm used in machine learning for classification tasks. It is based on the Bayes theorem and assumes that the features are independent of each other, which means that the presence of one feature does not affect the probability of the presence of another feature.\n",
    "\n",
    "Gaussian Naive Bayes is particularly useful when the number of features is large and the number of training examples is small. It is a simple yet effective algorithm that has been successfully used in many applications, including text classification, spam filtering, and image recognition.\n",
    "\n",
    "### Walk-through\n",
    "\n",
    "Let's now take a look at how we can use create an ML model to correctly identify types of iris plants using the Gaussian Naive Bayes ML algorithm.\n",
    "\n",
    "\n",
    "\n",
    "**Step 1: Importing Libraries**\n",
    "\n",
    "Just like with in the previous example, we first need to import all the required libraries. As in the previous example, we will be using NumPy and Polars for data manipulation and we use the `train_test_split` function from `bastionlab.polars`. We will also need the `GaussianNB model` and `metrics` submodule from Bastionlab Linfa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from bastionlab.linfa.models import GaussianNB\n",
    "from bastionlab.linfa import metrics\n",
    "from bastionlab.polars import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Data Loading**\n",
    "\n",
    "For this example, we will use the Iris dataset, which is a popular dataset used for classification tasks. It contains 150 samples of iris flowers, each with four features: sepal length, sepal width, petal length, and petal width. The dataset is included in the scikit-learn library, which can be loaded using the `load_iris()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "# load iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "data = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_iris()` method returns an object to us with `data` and `target` attributes containing numpy ndarrays with the features matrix and target vector data. The returned object also contains some additional metadata attributes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Uploading to BastionLab**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to upload the input and target datasets to BastionLab. But first, we need to convert these numpy ndarrays into Polars DataFrames. We do this by providing Polars DataFrame constructor with our numpy ndarray objects and saving the returned Polars DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input data to a Polars DataFrame\n",
    "data = pl.DataFrame(data)\n",
    "\n",
    "# Convert target data to a Polars DataFrame\n",
    "target = pl.DataFrame(target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to upload the data and target dataframes to BastionLab using BastionLab's `send_df` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload data dataset\n",
    "remote_data = connection.client.polars.send_df(data, policy)\n",
    "\n",
    "# upload target dataset\n",
    "remote_target = connection.client.polars.send_df(target, policy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a `FetchableLazyFrame` instance of both the input and target data which we can work with in BastionLab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Preprocessing**\n",
    "\n",
    "In order to use further pre-processing and training functions in BastionLab, we must first convert our `FetchableLazyFrames` into `RemoteArrays` using the `to_array()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data FetchableLazyFrame to remote array\n",
    "remote_data = remote_data.to_array()\n",
    "\n",
    "# convert target FetchableLazyFrame to remote array\n",
    "remote_target = remote_target.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training our model, we need to split our data into training and testing sets. We will use the `train_test_split()` function from BastionLab Polars to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get testing and training X and Y arrays\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    remote_data, remote_target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the `test_size` to 0.2, we allocate 20% of our datasets for validation to check our model's performance.\n",
    "\n",
    "By setting `random_state` to an integer, which happens to be 42 but could be a different value, the function will produce the same test and training sets across different executions. The results are only changed if we change the integer value.\n",
    "\n",
    "The `train_test_split` method returns our training and testing X and Y data (input and target data) as remote arrays."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Training and Predicting**\n",
    "\n",
    "We can now train our Gaussian Naive Bayes model using the GaussianNB class from BastionLab Linfa. We will fit the model to the training data and use it to predict the labels of the testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model object\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Training the model\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the target values for the test set\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Evaluating the model**\n",
    "\n",
    "We will now evaluate the performance of our model using the accuracy score metric, which gives us the percentage of correctly classified instances:\n",
    "[UP TO HERE- EXPLAIN TO_ARRAY()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: FetchableLazyFrame(identifier=5be09565-36aa-46de-9e0e-9dfca3c1d134)\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred.to_array())\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that results of metrics are returned as a `RemoteDataFrame` and so, you would have to call `fetch` to see the results as a plain Polars DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 1)\n",
      "┌──────────┐\n",
      "│ accuracy │\n",
      "│ ---      │\n",
      "│ f32      │\n",
      "╞══════════╡\n",
      "│ 0.933333 │\n",
      "└──────────┘\n"
     ]
    }
   ],
   "source": [
    "print(accuracy.fetch())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this tutorial, we learned how to use Gaussian Naive Bayes for classification tasks using the Iris dataset. We loaded the data, sent it to the BastionLab server, preprocessed it, trained the model, and evaluated its performance using the accuracy score. Gaussian Naive Bayes is a simple yet effective algorithm that can be used for a variety of classification tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "------------------------------------------------------------------\n",
    "\n",
    "Logistic Regression is a widely used statistical method for analyzing a dataset in which there are one or more independent variables that determine an outcome. It is commonly used in various fields such as medicine, social sciences, and marketing for binary and multi-class classification problems. In this Jupyter notebook, we will explore binomial and multinomial logistic regression, their applications, and how to implement them BastionLab.\n",
    "\n",
    "### Types of Logistic Regression\n",
    "\n",
    "- [Binomial Logistic Regression](#binomial-logistic-regression)\n",
    "- [Multinomial Logistic Regression](#multinomial-logistic-regression)\n",
    "  \n",
    "We will start with binomial logistic regression and then move on to multinomial logistic regression.\n",
    "\n",
    "We will use the following Python libraries:\n",
    "\n",
    "* Pandas - for loading and manipulating the dataset\n",
    "* BastionLab Linfa - for building and evaluating the logistic regression models\n",
    "* Scikit-learn - for fetching the dataset.\n",
    "\n",
    "\n",
    "We will be using the famous Iris dataset directly from sklearn which contains information about various flowers. The goal of the classification task is to predict the species of the flower based on its features.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial Logistic Regression\n",
    "\n",
    "#### Overview\n",
    "\n",
    "Binomial logistic regression is a statistical method used to model the relationship between a binary target variable and one or more independent variables. It is commonly used in classification tasks where the target variable has only two possible outcomes.\n",
    "\n",
    "#### Applications\n",
    "Binomial logistic regression is widely used in various fields such as medicine, social sciences, and marketing. It can be used to predict the likelihood of a patient having a disease based on their symptoms, the likelihood of a customer purchasing a product based on their demographic information, and more.\n",
    "\n",
    "#### Implementation\n",
    "In this section, we will demonstrate how to implement binomial logistic regression using Python and Scikit-learn.\n",
    "\n",
    "**Step 1: Importing Libraries**\n",
    "The first step is to import the required libraries. We will be using Polars for data manipulation, BastionLab Polars for creating training and testing sub-datasets, and BastionLab Linfa for building the Binomial Logistic Regression model and using the metrics submodule for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from bastionlab.linfa.models import LogisticRegression\n",
    "from bastionlab.linfa import metrics\n",
    "from bastionlab.polars import train_test_split\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Loading the Iris Dataset**\n",
    "\n",
    "The next step is to load the data into a Polars DataFrame. We will be using the Iris dataset, which contains information about various flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "inputs = pl.DataFrame(iris.data)\n",
    "target = pl.DataFrame(iris.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Uploading Data to BastionLab**\n",
    "\n",
    "The iris dataset loaded from scikit-learn would have to be first uploaded onto BastionLab. The effect of this step is akin to only having access to the remote data to apply the Logistic Regression algorithm to, and you will also be using the [policy](###setting-up-the-privacy-policy) set up above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_inputs = connection.client.polars.send_df(inputs, policy)\n",
    "remote_target = connection.client.polars.send_df(target, policy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Preprocessing**\n",
    "\n",
    "Before building the model, we need to prepare the data. This involves converting the target variable to a binary form and splitting the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_target = remote_target.select(\n",
    "    pl.when(pl.all() == 0).then(0).otherwise(1)\n",
    ").collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using our `RemoteDataFrame`s, we have to convert them into `RemoteArray`s.\n",
    "\n",
    "We use the `to_array` method to convert them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_inputs = remote_inputs.to_array()\n",
    "remote_target = remote_target.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we split our dataset into training and testing subsets with the snippet below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    remote_inputs, remote_target, test_size=0.3, random_state=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Building the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model object\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Training the model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the target values for the test set\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Model Evaluation**\n",
    "\n",
    "Finally, we can evaluate the model using metrics such as accuracy score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that results of metrics are returned as a `RemoteDataFrame` and so, you would have to call `fetch` to see the results as a plain Polars DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FetchableLazyFrame(identifier=ccad625d-f369-4a8a-94b4-ed81f13987f1)\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 1)\n",
      "┌──────────┐\n",
      "│ accuracy │\n",
      "│ ---      │\n",
      "│ f32      │\n",
      "╞══════════╡\n",
      "│ 0.521739 │\n",
      "└──────────┘\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy.fetch()\n",
    "print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "In this tutorial, we have learned about binomial logistic regression and its application in binary classification problems. We started by understanding the logistic function, which is the core of logistic regression. Then we discussed the key components of logistic regression, including the dependent variable, independent variables, and the maximum likelihood estimation method."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression\n",
    "\n",
    "#### Overview\n",
    "Logistic Regression is a popular algorithm used for binary classification problems. However, it can be extended to handle multi-class classification problems using the Multinomial Logistic Regression algorithm. The idea behind this algorithm is to train a separate binary logistic regression model for each class, where the output of each model is the probability of the input belonging to that class. The class with the highest probability is then selected as the predicted class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation\n",
    "\n",
    "**Step 1: Importing Libraries**\n",
    "The first step is to import the required libraries. We will be using Polars for data manipulation, BastionLab Polars for creating training and testing sub-datasets, and BastionLab Linfa for building the Multinomial Logistic Regression model and using the metrics submodule for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from bastionlab.linfa.models import LogisticRegression\n",
    "from bastionlab.linfa import metrics\n",
    "from bastionlab.polars import train_test_split\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Loading the Iris Dataset**\n",
    "\n",
    "The next step is to load the data into a Polars DataFrame. We will be using the Iris dataset, which contains information about various flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "inputs = pl.DataFrame(iris.data)\n",
    "target = pl.DataFrame(iris.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Uploading Data to BastionLab**\n",
    "\n",
    "The iris dataset loaded from scikit-learn would have to be first uploaded onto BastionLab. The effect of this step is akin to only having access to the remote data to apply the Logistic Regression algorithm to, and you will also be using the [policy](###setting-up-the-privacy-policy) set up above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_inputs = connection.client.polars.send_df(inputs, policy)\n",
    "remote_target = connection.client.polars.send_df(target, policy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Preprocessing**\n",
    "\n",
    "Before using our `RemoteDataFrame`s, we have to convert them into `RemoteArray`s.\n",
    "We use the `to_array` method to convert them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_inputs = remote_inputs.to_array()\n",
    "remote_target = remote_target.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we split our dataset into training and testing subsets with the snippet below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    remote_inputs, remote_target, test_size=0.2, random_state=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Building the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model object\n",
    "lr = LogisticRegression(multi_class=\"multinomial\", max_iter=1000)\n",
    "\n",
    "# Training the model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the target values for the test set\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Model Evaluation**\n",
    "\n",
    "Finally, we can evaluate the model using metrics such as accuracy score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that results of metrics are returned as a `RemoteDataFrame` and so, you would have to call `fetch` to see the results as a plain Polars DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FetchableLazyFrame(identifier=569c80a3-6fb5-461b-8b92-81b87f172d8f)\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 1)\n",
      "┌──────────┐\n",
      "│ accuracy │\n",
      "│ ---      │\n",
      "│ f32      │\n",
      "╞══════════╡\n",
      "│ 1.0      │\n",
      "└──────────┘\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy.fetch()\n",
    "print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "In this tutorial, we have learned about multinomial logistic regression and its application in binary classification problems. We started by understanding the logistic function, which is the core of logistic regression. Then we discussed the key components of logistic regression, including the dependent variable, independent variables, and the maximum likelihood estimation method."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "### Overview\n",
    "Decision Trees is a supervised machine learning algorithm used for both classification and regression tasks. It works by recursively splitting the data into subsets based on the values of the features and predicting the target variable based on the subset it belongs to.\n",
    "\n",
    "### Applications\n",
    "Decision Trees is widely used in various fields such as finance, medicine, and marketing.\n",
    "\n",
    "### Implementation\n",
    "In this section, we will demonstrate how to implement Decision Trees using BastionLab.\n",
    "\n",
    "**Step 1: Importing Libraries**\n",
    "\n",
    "The first step is to import the required libraries. We will be using Polars for data manipulation, and BastionLab for building the Decision Trees model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from bastionlab.linfa.models import DecisionTreeClassifier\n",
    "from bastionlab.linfa import metrics\n",
    "from bastionlab.polars import train_test_split\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Loading Data**\n",
    "\n",
    "The next step is to load the data into a Polars DataFrame. We will be using the Iris dataset.\n",
    "\n",
    "A well-known and commonly used dataset in the field of machine learning is the Iris dataset. Sepal length, sepal width, petal length, and petal breadth are the four characteristics that each sample of 150 iris flowers has. When using this dataset for classification tasks, the goal is to identify the species of iris flower based on these four characteristics.\n",
    "\n",
    "Iris setosa, Iris versicolor, and Iris virginica are the three classes of iris blooms represented in the dataset. There are 50 examples in each class, making 150 samples overall in the dataset. Sepal length and width, as well as petal length and width, are all measured in centimeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "inputs = pl.DataFrame(iris.data)\n",
    "target = pl.DataFrame(iris.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Uploading Data to BastionLab**\n",
    "\n",
    "The iris dataset loaded from scikit-learn would have to be first uploaded onto BastionLab. The effect of this step is akin to only having access to the remote data to apply the Logistic Regression algorithm to, and you will also be using the [policy](###setting-up-the-privacy-policy) set up above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_inputs = connection.client.polars.send_df(inputs, policy)\n",
    "remote_target = connection.client.polars.send_df(target, policy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Preprocessing**\n",
    "\n",
    "Before using our `RemoteDataFrame`s, we have to convert them into `RemoteArray`s.\n",
    "We use the `to_array` method to convert them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_inputs = remote_inputs.to_array()\n",
    "remote_target = remote_target.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we split our dataset into training and testing subsets with the snippet below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    remote_inputs, remote_target, test_size=0.2, random_state=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Building the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model object\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "# Training the model\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the target values for the test set\n",
    "y_pred = dtc.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Model Evaluation**\n",
    "\n",
    "Finally, we can evaluate the model using metrics such as accuracy score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that results of metrics are returned as a `RemoteDataFrame` and so, you would have to call `fetch` to see the results as a plain Polars DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FetchableLazyFrame(identifier=8f18c983-c028-4f9b-bb55-5c708f5f11df)\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 1)\n",
      "┌──────────┐\n",
      "│ accuracy │\n",
      "│ ---      │\n",
      "│ f32      │\n",
      "╞══════════╡\n",
      "│ 1.0      │\n",
      "└──────────┘\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy.fetch()\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59ddfbf641a892a32521b7a5e13e78d6d7d30d99a8ba692cb7ed0e595686b0db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
