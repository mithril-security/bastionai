{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"colab_button\">\n",
    "  <h1>Introduction to Machine Learning Algorithms with BastionLab</h1>\n",
    "  <a target=\"_blank\" href=\"https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.7/docs/docs/how-to-guides/introduction_to_ml_algorithms_with_bastionlab.ipynb\"> \n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "</div>\n",
    "______________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Machine learning is a subfield of artificial intelligence that focuses on the development of algorithms that can learn from and make predictions or decisions on data. Machine learning algorithms have become increasingly important in various fields such as medicine, finance, and marketing. In this Jupyter notebook, we will explore five popular machine learning algorithms, their applications, and how to implement them using Python and Scikit-learn.\n",
    "\n",
    "The five algorithms we will cover are:\n",
    "\n",
    "1. Linear Regression - for predicting continuous values\n",
    "2. Gaussian Naive Bayes - for classification problems with continuous features\n",
    "3. KMeans - for clustering data points into groups\n",
    "4. Decision Trees - for classification and regression problems\n",
    "5. Logistic Regression - for binary and multi-class classification problems\n",
    "\n",
    "We will be using various datasets to illustrate the applications of these algorithms.\n",
    "\n",
    "Let's dive in and explore these machine learning algorithms!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "----------\n",
    "1. [Linear Regression](#linear-regression)\n",
    "2. [Gaussian Naive Bayes](#gaussian-naive-bayes)\n",
    "3. [KMeans](#kmeans)\n",
    "4. [Decision Trees](#decision-trees)\n",
    "5. [Logistic Regression](#logistic-regression)\n",
    "    - [Binomial Logistic Regression](#binomial-logistic-regression)\n",
    "    - [Multinomial Logistic Regression](#multinomial-logistic-regression)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "________________________________________________\n",
    "### Installation\n",
    "\n",
    "This tutorial is intended for individuals with a basic understanding of Python programming language and some familiarity with the following libraries:\n",
    "\n",
    "In order to run this notebook, we need to:\n",
    "- Have [Python3.7](https://www.python.org/downloads/) (or greater) and [Python Pip](https://pypi.org/project/pip/) installed\n",
    "- Install [BastionLab](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/)\n",
    "- Install [Numpy](https://pypi.org/project/numpy)\n",
    "- Install [scikit-learn](https://pypi.org/project/scikit-learn)\n",
    "\n",
    "We'll do so by running the code block below. \n",
    "\n",
    ">If you are running this notebook on your machine instead of [Google Colab](https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.7/docs/docs/how-to-guides/introduction_to_ml_algorithms_with_bastionlab.ipynb), you can see our [Installation page](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/) to find the installation method that best suits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bastionlab\n",
    "!pip install bastionlab_server\n",
    "!pip install numpy\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a connection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before jumping into the tutorial, we will have to set up a connection to the BastionLab server. You will use the snippet below to create a connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bastionlab import Connection\n",
    "\n",
    "connection = Connection(\"localhost\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition warning\">\n",
    "    Please note that the above connection created is an insecure connection. You can refer to the <a href=\"https://github.com/mithril-security/bastionlab/blob/master/docs/docs/tutorials/authentication.ipynb\">Authentication tutorial</a> to learn about setting up secure connections to the BastionLab server.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the privacy policy\n",
    "\n",
    "Using BastionLab client, we'll upload our data to the server in a secure and private way. To do so, we need to define a custom privacy policy that will require two parameters.\n",
    "\n",
    "- A `safe_zone` which is a condition any request must meet to be considered privacy-preserving.\n",
    "- An `unsafe_handling` which is the action taken in case a request violates the `safe_zone`.\n",
    "\n",
    "For the purpose of this tutorial, we'll use the following:\n",
    "- Any request that aggregates at least 10 rows of the original DataFrame is safe,\n",
    "- We decide to log any offending request on the server side, so the Data Owner can see it.\n",
    "\n",
    "To send the DataFrame with the privacy policy to the server, we'll use the `send_df()` method of the `polars` interface of the client. We'll pass it our custom policy and a list of columns to be sanitized (*meaning set to null*) if retrieved by the data scientist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kwabena/base/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bastionlab.polars.policy import Policy, Aggregation, Log\n",
    "\n",
    "policy = Policy(\n",
    "    safe_zone=Aggregation(min_agg_size=10), unsafe_handling=Log(), savable=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To keep this overview short and simple, we will use weak but reasonable guarantees. If you're interested in setting up stricter policies, you are encouraged to have a look at our [Privacy policy tutorial](https://github.com/mithril-security/bastionlab/blob/master/docs/docs/tutorials/policy.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "### Overview\n",
    "Linear Regression is a supervised learning algorithm used for predicting a continuous outcome variable (also known as the response variable) based on one or more predictor variables. In other words, it is a technique for modeling the relationship between a dependent variable (Y) and one or more independent variables (X).\n",
    "\n",
    "The goal of Linear Regression is to find the best-fit line or hyperplane that describes the relationship between the independent and dependent variables. This line or hyperplane is defined by a set of coefficients that determine the slope and intercept of the line or hyperplane.\n",
    "\n",
    "Linear Regression is a widely used algorithm in machine learning and is used in various applications such as stock price prediction, sales forecasting, and many others. In this notebook, we will explore the basics of Linear Regression and its implementation using BastionLab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications\n",
    "\n",
    "Applications\n",
    "Linear Regression is widely used in various fields such as finance, economics, healthcare, and social sciences. Some of its applications include:\n",
    "\n",
    "* Predicting stock prices\n",
    "* Forecasting sales revenue\n",
    "* Estimating the impact of a marketing campaign on sales\n",
    "* Predicting the price of a house based on its features such as size, location, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "In this section, we will demonstrate how to implement Linear Regression using BastionLab.\n",
    "\n",
    "**Step 1: Importing Libraries**\n",
    "\n",
    "The first step is to import the required libraries. We will be using NumPy and Polars for data manipulation, and BastionLab Linfa for building the Linear Regression model and using the metrics submodule for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from bastionlab.linfa import LinearRegression\n",
    "from bastionlab.linfa.metrics import mean_squared_error\n",
    "from bastionlab.polars import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Loading Data**\n",
    "\n",
    "The California Housing dataset is a popular dataset used in machine learning and statistics. It is a real-world dataset that contains information collected from the 1990 California census. The dataset includes information on housing prices, demographics, and geography for each block group in California.\n",
    "\n",
    "Each row in the dataset represents a block group, which is the smallest geographic unit for which the US Census Bureau provides data. The dataset contains 20,640 observations and 8 attributes, including the median house value, median income, housing occupancy rate, and more.\n",
    "\n",
    "The goal of this tutorial is to use the California Housing dataset to predict housing prices using linear regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.fetch_california_housing(as_frame=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we use the load_boston function to load the California Housing dataset and return both the feature matrix X and the target vector y. When `as_frame=True` is set, it will return both our `data or X` and `targets or Y` as pandas `DataFrames` together metadata about the dataset. \n",
    "\n",
    "We will convert the pandas DataFrames into Polars DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inputs from Pandas DataFrame into Polars DataFrame\n",
    "inputs = pl.DataFrame(data[\"data\"])\n",
    "\n",
    "# Convert target into Polars DataFrame from Numpy Ndarray\n",
    "target = pl.DataFrame(data[\"target\"].to_numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data in all the right forms (in a Polars DataFrame for BastionLab,) we can go ahead and perform remote data operations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending the California Housing dataset to BastionLab\n",
    "\n",
    "In this tutorial, we assume that the data owner has a private dataset they want to explore. As they don't have the expertise, they would like to hire a data scientist and give them restricted access to their private data.\n",
    "\n",
    "In this part, we'll see how to **upload a data frame** to the server and use the [policy](###setting-up-the-privacy-policy) set up above. It is key to know that BastionLab ensures that **the original dataset cannot be downloaded by the data scientist**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_inputs = connection.client.polars.send_df(inputs, policy)\n",
    "remote_target = connection.client.polars.send_df(target, policy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The server returns a `FetchableLazyFrame` which is a reference to the remote DataFrame. It can be used as if it were locally available. We'll see how to use it in the data scientist's side section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Data Preparation**\n",
    "\n",
    "Before building the model, we need to prepare the data. This involves splitting the data into training and testing sets, scaling the data, and handling missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_X = remote_inputs.to_array()\n",
    "remote_Y = remote_target.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition important\">\n",
    "    `to_array` is BastionLab's implementation which is used to convert a `RemoteDataFrame` into an Ndarray on the server.\n",
    "    Once the method is called on the RemoteDataFrame, it's eagerly converted into a RemoteArray which is related to an Ndarray on the server.\n",
    "    If you want to know more about it, checkout our <a href=\"#\">data conversion tutorial</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    remote_X,\n",
    "    remote_Y,\n",
    "    test_size=0.3,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_test_split` just like in `sklearn`, is used to split the RemoteArray into train and test parts.\n",
    "In this example, the test size is set as 30% of the whole dataset and this will be used to validate that the model was fit properly.\n",
    "\n",
    "Also, we enable shuffling to improve the fitting of our model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Building the Model**\n",
    "\n",
    "We can now build the Linear Regression model using Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Training the model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the target values for the test set\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Model Evaluation**\n",
    "\n",
    "Finally, we can evaluate the model using metrics such as Mean Squared Error (MSE) and R-Squared (R^2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FetchableLazyFrame(identifier=12dda597-0cba-48cb-aad5-337774263108)\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred.to_array())\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that results of metrics are returned as a `RemoteDataFrame` and so, you would have to call `fetch` to see the results as a plain Polars DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 1)\n",
      "┌────────────────────┐\n",
      "│ mean_squared_error │\n",
      "│ ---                │\n",
      "│ f64                │\n",
      "╞════════════════════╡\n",
      "│ 0.53789            │\n",
      "└────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(mse.fetch())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The tutorial introduced the Linear Regression algorithm for regression tasks and showed how to apply it to the California Housing dataset using Bastionlab's machine learning module `linfa`. \n",
    "\n",
    "The tutorial covered data loading, splitting data into training and testing sets, creating a Linear Regression model instance, fitting the model to the training data, making predictions on the testing data, and evaluating the model's performance using the mean squared error metric. \n",
    "\n",
    "By the end of the section, you had built a simple Linear Regression model, trained it on real-world data, and evaluated its performance using a standard evaluation metric."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes\n",
    "### Overview\n",
    "\n",
    "Gaussian Naive Bayes is a probabilistic algorithm used in machine learning for classification tasks. It is based on the Bayes theorem and assumes that the features are independent of each other, which means that the presence of one feature does not affect the probability of the presence of another feature.\n",
    "\n",
    "Gaussian Naive Bayes is particularly useful when the number of features is large and the number of training examples is small. It is a simple yet effective algorithm that has been successfully used in many applications, including text classification, spam filtering, and image recognition.\n",
    "\n",
    "### Implementation\n",
    "\n",
    "**Step 1: Importing Libraries**\n",
    "\n",
    "The first step is to import the required libraries. We will be using NumPy and Polars for data manipulation, BastionLab Polars for creating training and testing sub-datasets, and BastionLab Linfa for building the Gaussian Naive Bayes Regression model and using the metrics submodule for validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from bastionlab.linfa import GaussianNB, metrics\n",
    "from bastionlab.polars import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Data Loading**\n",
    "\n",
    "In this tutorial, we will use the Iris dataset, which is a popular dataset used for classification tasks. It contains 150 samples of iris flowers, each with four features: sepal length, sepal width, petal length, and petal width. The dataset is included in the scikit-learn library, which can be loaded using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Uploading to BastionLab**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris dataset loaded from scikit-learn would have to be first uploaded onto BastionLab. The effect of this step is akin to only having access to the remote data to apply the Naive Bayes algorithm to, and you will also be using the [policy](###setting-up-the-privacy-policy) set up above. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded data would be converted into a Polars DataFrame, which is BastionLab's input type. The snippet below takes the Numpy ndarrays received and converts them into a Polars DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.DataFrame(data)\n",
    "target = pl.DataFrame(target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we upload the data and target dataframes to have their remote representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_data = connection.client.polars.send_df(data, policy)\n",
    "remote_target = connection.client.polars.send_df(target, policy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remote data will be converted into `RemoteArray` because our training function and the preprocessing functions accepts `RemoteArray`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_data = remote_data.to_array()\n",
    "remote_target = remote_target.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Preprocessing**\n",
    "\n",
    "Before training our model, we need to preprocess the remote data by splitting it into training and testing sets. We will use the train_test_split() function from BastionLab Polars to split the data into 80% training set and 20% testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    remote_data, remote_target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Training and Predicting**\n",
    "\n",
    "We can now train our Gaussian Naive Bayes model using the GaussianNB class from BastionLab Linfa. We will fit the model to the training data and use it to predict the labels of the testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Evaluating the model**\n",
    "\n",
    "To evaluate the performance of our model, we can use various metrics such as accuracy, precision, recall, and F1-score. In this tutorial, we will use the accuracy score, which measures the percentage of correctly classified instances:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before passing our `y_pred` to the `accuracy_score` function, we ought to convert it into a `RemoteArray` because the results of the `predict` was a `RemoteDataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: FetchableLazyFrame(identifier=9c5504ca-ced8-474d-878b-03a010a97d87)\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that results of metrics are returned as a `RemoteDataFrame` and so, you would have to call `fetch` to see the results as a plain Polars DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 1)\n",
      "┌──────────┐\n",
      "│ accuracy │\n",
      "│ ---      │\n",
      "│ f32      │\n",
      "╞══════════╡\n",
      "│ 0.933333 │\n",
      "└──────────┘\n"
     ]
    }
   ],
   "source": [
    "print(accuracy.fetch())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this tutorial, we learned how to use Gaussian Naive Bayes for classification tasks using the Iris dataset. We loaded the data, sent it to the BastionLab server, preprocessed it, trained the model, and evaluated its performance using the accuracy score. Gaussian Naive Bayes is a simple yet effective algorithm that can be used for a variety of classification tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b02da7949da3af218e39ce2f31e32c0a1b93d864bdc2c2f7ec5cedc3569d5902"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
