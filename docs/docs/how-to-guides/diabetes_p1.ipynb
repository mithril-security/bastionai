{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jdvo0Bjb_G1c"
   },
   "source": [
    "<div id=\"colab_button\">\n",
    "  <h1>Data exploration of diabetes hospital admissions: Part I </h1>\n",
    "  <a target=\"_blank\" href=\"https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.7/docs/docs/how-to-guides/diabetes_p1.ipynb\"> \n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "</div>\n",
    "______________________________________________________\n",
    "\n",
    "Despite major technological breakthroughs in cybersecurity and privacy in recent years, secure off-premises data science collaboration has remained out of reach. This is a major problem for the health sector which has so much to gain from the power of data but also so much at risk when it comes to patients' highly sensitive medical records.\n",
    "\n",
    "We are on a mission to make remote data science collaboration safe for the health sector. Using BastionLab, data owners can set strict access policies on datasets for collaborators, allowing them to run privacy-friendly queries and train and deploy ML models on datasets whilst blocking access to raw data.\n",
    "\n",
    "In this how-to guide, we will explore a dataset of diabetic patients admitted to hospital in the US over a ten year period. Diabetes is a disease that affects over 10% of the US population and can lead to serious health complications. The dataset contains 51 columns of data, including readmission to hospital, changes to medication and primary, secondary and terciary patient diagnoses.\n",
    "\n",
    "In part I of this two-part data exploration. We will see how the data owner can upload a dataset to BastionLab and how a data scientist can then connect to BastionLab and **clean the dataset**.\n",
    "\n",
    "But before we can do that, we first need to get everything set up!\n",
    "\n",
    "## Pre-requisites\n",
    "___________________________________________\n",
    "\n",
    "### Installation and dataset\n",
    "\n",
    "In order to run this notebook, we need to:\n",
    "- Ensure we have [Python3.7](https://www.python.org/downloads/) (or greater) and [Python Pip](https://pypi.org/project/pip/) installed\n",
    "- Install [BastionLab](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/) and the [BastionLab server](https://pypi.org/project/bastionlab-server/0.3.7/) pip packages\n",
    "- [Download the dataset](https://drive.google.com/file/d/1NPQoKKG3CdvXTNkHVNYhRQZ8GGiPNlvI/view?usp=share_link) we will be using in this notebook.\n",
    "\n",
    "You can download the BastionLab pip packages and the dataset by running the following code block.\n",
    "\n",
    ">To find out about other ways you can install and run BastionLab, see our [Installation page](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hK-HDaMI_G1j"
   },
   "outputs": [],
   "source": [
    "# installing BastionLab client & server packages\n",
    "!pip install bastionlab\n",
    "!pip install bastionlab_server\n",
    "\n",
    "# dowloading the dataset using Google Drive tool dgown\n",
    "!pip install gdown\n",
    "!pip install --upgrade --no-cache-dir gdown\n",
    "!gdown --id \"1NPQoKKG3CdvXTNkHVNYhRQZ8GGiPNlvI\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NJ67chDB_G1l"
   },
   "source": [
    "The dataset we are using for this how-to guide is based on the Diabetes 130-US hospitals for years 1999-2008 dataset. It contains 10 years of data on diabetes admissions from 130 US hospitals. It includes over 50 features representing patient and hospital outcomes.\n",
    "\n",
    ">For more detailed information on the dataset, you can check out the description and full dataset by following this [link](https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008).\n",
    "\n",
    "However, this dataset had already been pre-processed before publication which stopped us from showing you some key data cleaning steps. We therefore made a few modifications to replace some pre-grouped data columns with randomly populated data. You can check out exactly how we did this using Polars [here](https://colab.research.google.com/drive/174EJvK8u8mGGWb6ypLH9SKaeRnX-pEou?usp=share_link). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OjL01I5c_G1m"
   },
   "source": [
    "## Data owner's POV\n",
    "___________________________________________\n",
    "\n",
    "### Launching the server\n",
    "\n",
    "Let's start by putting ourselves in the shoes of the data owner.\n",
    "\n",
    "But before we can do anything more, the BastionLab server must be running.\n",
    "\n",
    "In production we recommend this is done using our Docker image, but for testing purposes you can use our `bastionlab_server` package, which removes the need for user authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A85GsYOi_G1o",
    "outputId": "29d2505e-8106-4311-cba2-05d1ae6101ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BastionLab server (version 0.3.7) already installed\n",
      "Libtorch (version 1.13.1) already installed\n",
      "TLS certificates already generated\n",
      "Bastionlab server is now running on port 50056\n"
     ]
    }
   ],
   "source": [
    "# launch bastionlab_server test package\n",
    "import bastionlab_server\n",
    "\n",
    "srv = bastionlab_server.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBWNyTnz_G1p"
   },
   "source": [
    ">*For more details on how you can set up the server using our Docker image, check out our [Installation Tutorial](../getting-started/installation.md).*\n",
    "\n",
    "### Connecting to the server\n",
    "Next, we will connect to the server in order to be able to upload the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6zzV7xrs_G1q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-02-17T16:18:15Z INFO  bastionlab] Authentication is disabled.\n",
      "[2023-02-17T16:18:15Z INFO  bastionlab] Telemetry is enabled.\n",
      "[2023-02-17T16:18:15Z INFO  bastionlab] BastionLab server listening on 0.0.0.0:50056.\n",
      "[2023-02-17T16:18:15Z INFO  bastionlab] Server ready to take requests\n"
     ]
    }
   ],
   "source": [
    "# connecting to the server\n",
    "from bastionlab import Connection\n",
    "\n",
    "connection = Connection(\"localhost\")\n",
    "client = connection.client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9DO7gVt_G1r"
   },
   "source": [
    "### Creating a custom privacy policy\n",
    "\n",
    "We can now create a [custom access policy](https://bastionlab.readthedocs.io/en/latest/docs/tutorials/defining_policy_privacy/) for the dataset which determines how much access collaborators will get to the dataset. \n",
    "\n",
    "In this example, we create a policy with the following configuration:\n",
    "\n",
    "->  `Aggregation(min_agg_size=10):` Any data extracted from the dataset should be the result of an aggregation of at least ten rows.\n",
    "\n",
    "->  `unsafe_handling=Reject()`: Any attempted query which breaches this policy will be rejected by the server.\n",
    "\n",
    "->  `savable=True`: The data scientist can save changes made to the dataset in BastionLab (this will create a new dataset- it will not overwrite the original dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mRJjgd1C_G1t"
   },
   "outputs": [],
   "source": [
    "from bastionlab.polars.policy import Policy, Aggregation, Reject\n",
    "\n",
    "# defining the dataset's privacy policy\n",
    "policy = Policy(Aggregation(min_agg_size=10), unsafe_handling=Reject(), savable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7HHSM3e_G1v"
   },
   "source": [
    "### Uploading the dataset\n",
    "\n",
    "Now that the policy has been created, we can upload the dataset to the BastionLab server instance.\n",
    "\n",
    "Firstly, we need to convert our CSV file into a Polars DataFrame by using the Polars `read_csv` function, supplying the path to the CSV file as a string argument.\n",
    "\n",
    "Next, we use BastionLab's `client.polars.send_df` to upload the dataframe with our custom policy.\n",
    "\n",
    "Finally, we save the FetchableLazyFrame using the `save` method with no arguments. We can make a note of the FetchableLazyFrame's identifier to be shared with data scientists to help them to remotely access the FetchableLazyFrame!\n",
    "\n",
    ">Note we need to save FetchableLazyFrames to avoid them being lost when the server is stopped and restarted or crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lkMIl0ar_G1w",
    "outputId": "836022c7-273a-4f98-cc84-baf1721c3412"
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# converting the dataset into a Polars dataframe\n",
    "df = pl.read_csv(\"updated_diabetes_data.csv\")\n",
    "\n",
    "# uploading the dataframe, the custom privacy policy\n",
    "# and the column we want to forbid to BastionLab's server\n",
    "rdf = client.polars.send_df(df, policy=policy)\n",
    "\n",
    "# saving the RemoteLazyFrame\n",
    "rdf.save()\n",
    "# get and print out a copy of the RDF identifier string\n",
    "ID = rdf.identifier\n",
    "print(ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywAyp-2y_G1y"
   },
   "source": [
    "`send_df()` will return a FetchableLazyFrame instance, which we will work with directly from now on. \n",
    "\n",
    ">Note that we talk about two types of LazyFrames in BastionLab: `RemoteLazyFrames` and `FetchableLazyFrames`. \n",
    "\n",
    "A `RemoteLazyFrame` just means we have called some functions and not yet `collected` the results, which means the operations have not yet been run on the server-side. When we call `collect()` these operations are run server-side and the result of this is our `FetchableLazyFrame`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRC1y4uX_G10"
   },
   "source": [
    "Let's finish off by testing what happens if we breach our security policy by trying to display an entire column from our dataset with the `collect().fetch()` methods. \n",
    "\n",
    ">*You can learn more about how to use both of those methods in [our quick tour](https://bastionlab.readthedocs.io/en/latest/docs/quick-tour/quick-tour/#running-queries).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C7j4vdDd_G10",
    "outputId": "cfa18f9b-5606-4e38-ba96-b6bcbf4b44a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mThe query has been rejected by the data owner.\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "rdf.select(\"age\").collect().fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1Zu2YQi_G11"
   },
   "source": [
    "Instead of getting back the results of our query, we see an error message: `The query has been rejected by the data owner.`\n",
    "\n",
    "We cannot view the output of the query because it does not aggregate at least 10 rows of data as specified in our privacy policy. It tries to print out individual rows instead!\n",
    "\n",
    "Now that the dataset has been uploaded, it's time for our data scientists to get working... \n",
    "\n",
    "The data owner can now connection their connection to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcM4pR6D_G11"
   },
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJzNveFG_G13"
   },
   "source": [
    "## Data scientist #1's POV\n",
    "__________________________________________\n",
    "\n",
    "### Connecting to the dataset\n",
    "\n",
    "We'll now jump into the role of the data scientist responsible for cleaning the dataset for this data analysis project.\n",
    "\n",
    "We first need to connect to the `bastion_lab` server and get a FetchableLazyFrame instance of the dataset. We'll use' the `get_df()` method and supply it with the id shared with us by the data owner to do this.\n",
    "\n",
    "We store our FetchableLazyFrame in the `rdf` variable which we'll be working with from here on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TT3mSjII_G13",
    "outputId": "3e048fa0-5f0f-4244-f369-a9d87580b225"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchableLazyFrame(identifier=0c7f2bcc-5afc-4a0a-b10f-24d796195045)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = Connection(\"localhost\")\n",
    "client = connection.client\n",
    "\n",
    "# selecting the FetchableLazyFrame(s) we'll be working with\n",
    "rdf = client.polars.get_df(ID)\n",
    "rdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEFbeESX_G14"
   },
   "source": [
    "Let's display the dataset's columns to confirm we are connected to the correct one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G-g8rOnj_G15",
    "outputId": "8538d93f-bf36-456e-c028-90cd724dd829"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encounter_id', 'patient_nbr', 'race', 'gender', 'age', 'weight', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'time_in_hospital', 'payer_code', 'medical_specialty', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1', 'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted']\n"
     ]
    }
   ],
   "source": [
    "print(rdf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H55DTcKn_G15"
   },
   "source": [
    "Everything is as expected! We can now start our data exploration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQC7tfaF_G15"
   },
   "source": [
    "## Data cleaning\n",
    "__________________________________________\n",
    "\n",
    "\n",
    "### Dropping columns\n",
    "You may have noticed, this dataset contains a lot of columns! This is great as it it gives us a wide choice of correlations to explore. However, we will not have time to explore all of them in this analysis! We can therefore drop the columns that we won't be using- either because they are irrelavant, or because they didn't lead us to the most interesting correlations for this analysis!\n",
    "\n",
    "We can do this by using the`drop` method, providing it with a list of the names of columns to be dropped. This is a RemoteLazyFrame method which corresponds directly to the [Polars drop() function](https://pola-rs.github.io/polars/py-polars/html/reference/lazyframe/api/polars.LazyFrame.drop.html#polars.LazyFrame.drop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0NI6rTqOKWN"
   },
   "outputs": [],
   "source": [
    "# list of column names we wish to remove from our RemoteLazyFrame\n",
    "to_drop = [\n",
    "    \"encounter_id\",\n",
    "    \"patient_nbr\",\n",
    "    \"weight\",\n",
    "    \"discharge_disposition_id\",\n",
    "    \"admission_source_id\",\n",
    "    \"time_in_hospital\",\n",
    "    \"payer_code\",\n",
    "    \"medical_specialty\",\n",
    "    \"num_lab_procedures\",\n",
    "    \"num_procedures\",\n",
    "    \"num_medications\",\n",
    "    \"number_outpatient\",\n",
    "    \"number_inpatient\",\n",
    "    \"number_diagnoses\",\n",
    "    \"diabetesMed\",\n",
    "]\n",
    "\n",
    "# replace rdf with our updated RemoteLazyFrame with to_drop columns deleted\n",
    "rdf = rdf.drop(to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vabmc_jjOQCo"
   },
   "source": [
    "There are now 36 columns to work with intead of 51- this will make the RemoteLazyFrame a little easier to work with!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ausY-PC_G16"
   },
   "source": [
    "\n",
    "### Checking for null values\n",
    "\n",
    "We now want to assess how many null values we have in each column. This will help us to know if we have enough data to draw meaningful conclusions from each column and gives us the chance to fill or delete null values if relevant.\n",
    "\n",
    "However, based on the description of the dataset shared with us by the data owner, we know that some column cells have been filled with '?' instead of being left blank.\n",
    "\n",
    "Before we can get an accurate picture of null values, we first need to replace all these '?' values with null values. We will do this by using [Polars .when().then().otherwise()` functions](https://pola-rs.github.io/polars/py-polars/html/reference/expressions/api/polars.when.html). \n",
    "\n",
    "One final hurdle is that we can only search and replace '?' strings in columns containing strings which will have the 'Utf8' datatype- otherwise an error will be produced. We must therefore only apply our search and replace operation to string columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2KwhZB_fTC3"
   },
   "outputs": [],
   "source": [
    "# step one: getting a list of all Utf8/string columns\n",
    "selects = []\n",
    "for x in rdf.columns:\n",
    "    if rdf.select(x).dtypes == [pl.datatypes.Utf8]:\n",
    "        selects.append(x)\n",
    "\n",
    "# step two: we replace all '? cells in these columns with null values\n",
    "rdf = rdf.with_columns(\n",
    "    [\n",
    "        pl.when(pl.col(x) == \"?\").then(None).otherwise(pl.col(x)).keep_name()\n",
    "        for x in selects\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1Frpi9GUtdW"
   },
   "source": [
    "In step two, we use the Polars `with_columns` function to add our new columns with null values instead of question marks to our RemoteLazyFrame. By using the `keep_name` function, these columns keep their original column name and therefore replace the original columns in the dataset. We save the result as `rdf`, storing the updated version of the dataset in our `rdf` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMMX8JZnKitA"
   },
   "source": [
    "Now that this is done, we can go ahead and calculate how many null values each column contains.\n",
    "\n",
    "We do this by iterating over all the columns and getting a percentage of the `sum` of all the value that return `True` to the `is_null` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAqqUz6I_G16"
   },
   "outputs": [],
   "source": [
    "# getting every columns percentage of null values in the RemoteLazyFrame\n",
    "percent_missing = rdf.select(\n",
    "    [\n",
    "        pl.all().is_null().sum() * 100 / pl.all().count(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uMcNqVZWhdN"
   },
   "source": [
    "We can then view the percentage of null values for each column as a two-column list by using Polars `melt` function to flip the query results from a 2 row by 5 column grid, to a 2 column by 5 row grid. We use the `sort` function to show the columns in order from the column with the highest percentage of null values to the lowest.\n",
    "\n",
    "Finally, we remove any columns with no null values from our output since they are not of interest to us here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "Pzz5qvSJWd2V",
    "outputId": "26229368-72d0-4630-f8e2-5a12f480f297"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        line-height: 95%;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (7, 2)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "column name\n",
       "</th>\n",
       "<th>\n",
       "null values (%)\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;max_glu_serum&quot;\n",
       "</td>\n",
       "<td>\n",
       "94.746772\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;A1Cresult&quot;\n",
       "</td>\n",
       "<td>\n",
       "83.277322\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;readmitted&quot;\n",
       "</td>\n",
       "<td>\n",
       "53.911916\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;race&quot;\n",
       "</td>\n",
       "<td>\n",
       "2.233555\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;diag_3&quot;\n",
       "</td>\n",
       "<td>\n",
       "1.398306\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;diag_2&quot;\n",
       "</td>\n",
       "<td>\n",
       "0.351787\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;diag_1&quot;\n",
       "</td>\n",
       "<td>\n",
       "0.020636\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (7, 2)\n",
       "┌───────────────┬─────────────────┐\n",
       "│ column name   ┆ null values (%) │\n",
       "│ ---           ┆ ---             │\n",
       "│ str           ┆ f64             │\n",
       "╞═══════════════╪═════════════════╡\n",
       "│ max_glu_serum ┆ 94.746772       │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ A1Cresult     ┆ 83.277322       │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ readmitted    ┆ 53.911916       │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ race          ┆ 2.233555        │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ diag_3        ┆ 1.398306        │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ diag_2        ┆ 0.351787        │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ diag_1        ┆ 0.020636        │\n",
       "└───────────────┴─────────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melt table to a two-column table with the column name 'column' and corresponding percetage of null values 'null values', sort in descending order and display\n",
    "percent_missing = percent_missing.melt(\n",
    "    variable_name=\"column name\",\n",
    "    value_name=\"null values (%)\",\n",
    ").sort(pl.col(\"null values (%)\"), reverse=True)\n",
    "\n",
    "# filter out columns with no null values and display\n",
    "percent_missing.filter(pl.col(\"null values (%)\") > 0).collect().fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4n0jnBPyYLjf"
   },
   "source": [
    "There are several strategies for dealing with null values such as deleting these rows from the dataset with the `drop_nulls` method or filling null values with the `fill_null` method. But in our case, we are just happy to have visibility over which columns including null values and to what extent so that we can handle and analyse these columns with this in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WUugovwve2c"
   },
   "source": [
    "### Grouping data: ICD-9 medical codes\n",
    "Grouping data is going to be the largest and most crucial task in this data cleaning job. This is a dataset with a low of wide-ranging numerical values which need to be grouped so that our data analysts can gain meaningul insights.\n",
    "\n",
    "Let's start with our diagnoses columns: `diag_1`, `diag_2` and `diag_3`.\n",
    "\n",
    "These columns contain the primary, secondary and terciary diagnoses given to patients. These diagnoses are given using [ICD-9 medical codes](https://en.wikipedia.org/wiki/List_of_ICD-9_codes) which are three digit codes ranging from 1 to 1000, as well as E800–E999 codes and V01–V82 codes.\n",
    "\n",
    "By grabbing all the unique values in the `diag_1` column and counting them, we can see that we have over 700 different values in this column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "7pVHpmLWj6_w",
    "outputId": "c7d50a9f-f919-4893-a1f4-50b1ba7d20c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        line-height: 95%;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (1, 1)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "diag_1\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "u32\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "717\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌────────┐\n",
       "│ diag_1 │\n",
       "│ ---    │\n",
       "│ u32    │\n",
       "╞════════╡\n",
       "│ 717    │\n",
       "└────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = rdf.select(\"diag_1\").unique()\n",
    "tmp.select(pl.col(\"diag_1\").count()).collect().fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPsmfkBpkPCv"
   },
   "source": [
    "Standard groupings of these codes have already been designed. What we want to do is replace the hundreds of unique codes we have in our our diagnoses columns with these groupings!\n",
    "\n",
    "To do this, we will again use Polars `when().then().otherwise()` functions to  perform a find and replace operation. We will use `when()` to check if the codes in each cell are either E or V codes or fall within a certain numerical range.\n",
    "\n",
    "However, these diagnoses columns are currently string columns, since the E and V codes are not entirely numerical. This is problematic since we cannot perform numerical comparisons on these cells and we cannot convert the column type to a numerical one because of these 'E' and 'V' values!\n",
    "\n",
    "We will solve this problem in three steps:\n",
    "\n",
    "1) We will find and replace all E codes with a \"-1\" value and V codes with a \"-2\" value.\n",
    "\n",
    "2) We will `select()` our columns and `cast()` all values in these columns to float values.\n",
    "\n",
    "3) We will perform the find and replace operation to group all ICD-9 codes into their associated group- of which there are 17, plus E codes and V codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xPNFpZ7lW8qR"
   },
   "outputs": [],
   "source": [
    "# iterate over the three diagnoses columns\n",
    "for col in [\"diag_1\", \"diag_2\", \"diag_3\"]:\n",
    "    # step one: replace troublesome E and V codes with temporary -1 and -2 codes\n",
    "    rdf = rdf.with_columns(\n",
    "        [\n",
    "            pl.when(\n",
    "                pl.col(col).str.starts_with(\"E\")\n",
    "            )  # use Polars str.starts_with method to identify E codes\n",
    "            .then(\"-1\")\n",
    "            .when(pl.col(col).str.starts_with(\"V\"))\n",
    "            .then(\"-2\")\n",
    "            .otherwise(pl.col(col))\n",
    "            .keep_name()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # step two: cast all values in column to float values\n",
    "    rdf = rdf.with_columns([pl.col(col).cast(pl.Float64)])\n",
    "\n",
    "    # step three: replace all codes with their corresponding group\n",
    "    rdf = rdf.with_columns(\n",
    "        [\n",
    "            pl.when(pl.col(col) >= 800)\n",
    "            .then(\"injury and poisoning\")\n",
    "            .when(pl.col(col) >= 780)\n",
    "            .then(\"symptoms, signs & ill-defined\")\n",
    "            .when(pl.col(col) >= 760)\n",
    "            .then(\"perinatal\")\n",
    "            .when(pl.col(col) >= 740)\n",
    "            .then(\"congenital anomalies\")\n",
    "            .when(pl.col(col) >= 710)\n",
    "            .then(\"musculoskeletal & connective tissue\")\n",
    "            .when(pl.col(col) >= 680)\n",
    "            .then(\"skin\")\n",
    "            .when(pl.col(col) >= 630)\n",
    "            .then(\"pregnancy, childbirth and peurperium\")\n",
    "            .when(pl.col(col) >= 580)\n",
    "            .then(\"genitourinary\")\n",
    "            .when(pl.col(col) >= 520)\n",
    "            .then(\"digestive\")\n",
    "            .when(pl.col(col) >= 460)\n",
    "            .then(\"respiratory\")\n",
    "            .when(pl.col(col) >= 390)\n",
    "            .then(\"circulatory\")\n",
    "            .when(pl.col(col) >= 320)\n",
    "            .then(\"nervous system and sense organs\")\n",
    "            .when(pl.col(col) >= 290)\n",
    "            .then(\"mental disorders\")\n",
    "            .when(pl.col(col) >= 280)\n",
    "            .then(\"blood and blood-forming organs\")\n",
    "            .when(pl.col(col) >= 240)\n",
    "            .then(\"neoplasms\")\n",
    "            .when(pl.col(col) >= 140)\n",
    "            .then(\"endocrine, nutritional, metabolic and immunity\")\n",
    "            .when(pl.col(col) >= 1)\n",
    "            .then(\"infectious and parasitic\")\n",
    "            .when(pl.col(col) == -1)\n",
    "            .then(\"E code (injury\")\n",
    "            .when(pl.col(col) == -2)\n",
    "            .then(\"V code (other)\")\n",
    "            .otherwise(\n",
    "                pl.col(col)\n",
    "            )  # otherwise (null values) keep original value from the column\n",
    "            .alias(\n",
    "                col\n",
    "            )  # give resulting column same name as previously- therefore replacing old columns\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1MquUrNlXDO"
   },
   "source": [
    "By performing the same query as previously to count `diag_1`'s unique values, we see there is now a much more manageable 19 labels in our data column! This will be similar for the `diag_2` and `diag_3` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "YfC9CmWWdu0n",
    "outputId": "c81284d2-8e09-49b6-f411-512da2421902"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        line-height: 95%;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (1, 1)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "diag_1\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "u32\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "19\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌────────┐\n",
       "│ diag_1 │\n",
       "│ ---    │\n",
       "│ u32    │\n",
       "╞════════╡\n",
       "│ 19     │\n",
       "└────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = rdf.select(\"diag_1\").unique()\n",
    "tmp.select(pl.col(\"diag_1\").count()).collect().fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvdGu7GmsZVu"
   },
   "source": [
    "### Grouping data: A1C, max glucose levels and readmittance\n",
    "\n",
    "We want to group together data in another three other columns using the same `.then().when().otherwise()` methods.\n",
    "\n",
    "The first two are `A1Cresult`, which contains patients' HbA1c level, and `max_glu_serum`, which contains their blood glucose level. We want to group these into `very high`, `high`, `normal` groups based on levels defined in our project brief.\n",
    "\n",
    "These columns are both currently string columns, so we will also need to convert them to float values in order to perform numerical comparisons on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgyrnPAlsZ0u"
   },
   "outputs": [],
   "source": [
    "# cast `max_glu_serum` and `A1Cresult` columns to float values\n",
    "rdf = rdf.with_columns(\n",
    "    [pl.col(\"max_glu_serum\").cast(pl.Float64), pl.col(\"A1Cresult\").cast(pl.Float64)]\n",
    ")\n",
    "\n",
    "# group values in A1Cresult column\n",
    "rdf = rdf.with_columns(\n",
    "    [\n",
    "        pl.when(pl.col(\"A1Cresult\") >= 8)\n",
    "        .then(\"very high\")\n",
    "        .when(pl.col(\"A1Cresult\") >= 7)\n",
    "        .then(\"high\")\n",
    "        .when(pl.col(\"A1Cresult\") >= 0)\n",
    "        .then(\"normal\")\n",
    "        .otherwise(pl.col(\"A1Cresult\"))\n",
    "        .keep_name()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# group values in max_glu_serum column\n",
    "rdf = rdf.with_columns(\n",
    "    [\n",
    "        pl.when(pl.col(\"max_glu_serum\") >= 300)\n",
    "        .then(\"very high\")\n",
    "        .when(pl.col(\"max_glu_serum\") >= 200)\n",
    "        .then(\"high\")\n",
    "        .when(pl.col(\"max_glu_serum\") >= 0)\n",
    "        .then(\"normal\")\n",
    "        .otherwise(pl.col(\"max_glu_serum\"))\n",
    "        .keep_name()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Buu2nja5w6Db"
   },
   "source": [
    "The final column we want to group is the `readmitted` column which records the number of days before any further re-hospitalization linked to the patients' diabetic condition.\n",
    "\n",
    "We will group this column into `short-term` and `long-term` and `n/a` (not applicable) groups.\n",
    "\n",
    "Simiar to in previous examples, we must first convert values in this column from strings to integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cca9DhSw6We"
   },
   "outputs": [],
   "source": [
    "# cast readmitted column to integer values\n",
    "rdf = rdf.with_columns([pl.col(\"readmitted\").cast(pl.Int64)])\n",
    "\n",
    "# group values\n",
    "rdf = rdf.with_columns(\n",
    "    [\n",
    "        pl.when(pl.col(\"readmitted\") < 31)\n",
    "        .then(\"short-term\")\n",
    "        .when(pl.col(\"readmitted\") >= 31)\n",
    "        .then(\"long-term\")\n",
    "        .otherwise(\"n/a\")\n",
    "        .keep_name()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuwxAGYBoOQJ"
   },
   "source": [
    "### Grouping data: binning ages\n",
    "The next grouping task we will perform is to group ages into intervals of 10 years. We do this both to increase data privacy and to more easily draw correlations linked to broader age groups.\n",
    "\n",
    "We won't need to perform an `when().then().otherwise()` query here since BastionLab has its own `ApplyBins` tool.\n",
    "\n",
    "`ApplyBins` is a PyTorch module and the grouping of numbers takes place in its `forward` function. We can pass PyTorch modules to BastionLab's `apply_udf` function which will apply the `forward` function to any specified columns.\n",
    "\n",
    "All in all, we just three steps to bin our age column data:\n",
    "\n",
    "1) We import `ApplyBins` from `bastionlab.polars.utils`.\n",
    "1) We instantiate our `ApplyBins` PyTorch module class with our bins interval given as the only argument.\n",
    "2) We use `apply_udf`, providing a list of the column we want to modify and the PyTorch module, `ApplyBins`, that we wish to apply to these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2EC3smnWc06Q"
   },
   "outputs": [],
   "source": [
    "from bastionlab.polars.utils import ApplyBins\n",
    "\n",
    "# get an instance of ApplyBins module which will bin data into groups of 10\n",
    "model = ApplyBins(10)\n",
    "\n",
    "# apply bins to \"age\" column\n",
    "rdf = rdf.apply_udf([\"age\"], model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pOQYPYSsVns"
   },
   "source": [
    "> Note, you can create your own custom PyTorch modules and apply them to columns using `apply_udf`. This is BastionLab's way of allowing you to apply custom functions on datasets, whilst restricting what you can do for security reasons. Functionality like `lambda`, `map` and `apply` are blocked by BastionLab as they are too permissive and could be misused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYRVmqTitckT"
   },
   "source": [
    "### Adding columns\n",
    "\n",
    "Up until this point we have been using the `.when().then().otherwise()` and `with_columns` methods to make changes to existing columns, but by providing a new column name to the `alias` method, we can create a new column.\n",
    "\n",
    "In the following example, we will create a `is_readmitted` column which will store `False` for all the \"n/a\" values in our original `readmitted` column and `True` for any other values. This will allow us to quickly query whether certain groups of data have been readmitted or not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2JGdBhmteAz"
   },
   "outputs": [],
   "source": [
    "rdf = rdf.with_columns(\n",
    "    [\n",
    "        pl.when(pl.col(\"readmitted\") == \"n/a\")\n",
    "        .then(False)\n",
    "        .otherwise(True)\n",
    "        .alias(\n",
    "            \"is_readmitted\"\n",
    "        )  # ending the .when().then().otherwise() pattern with .alias() allows us to provide a new column name\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edoL2_uy_G19"
   },
   "source": [
    "### Converting column types\n",
    "\n",
    "We have already seen examples where we have `explicity` converted the datatype of our columns using the `cast` method. Here we will `implicity` convert the datatype by replacing the \"yes\" and \"no\" values in our `change` column, which represent whether a patient's medication has been changed, to a boolean True or False value. \n",
    "\n",
    "The datatype of this column will be changed automatically by this operation as we can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fMhSrD8__G19",
    "outputId": "5230be79-58b9-4318-c5bb-052cd03e35d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[polars.datatypes.Utf8]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out initial datatype of \"change\" column\n",
    "\n",
    "rdf.select(\"change\").dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hYWJ9FB70mcM",
    "outputId": "cc2736c7-e4be-48dd-805d-352ba0d6196e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[polars.datatypes.Boolean]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replaces Yes/No values with True/False\n",
    "rdf = rdf.with_columns(\n",
    "    [pl.when(pl.col(\"change\") == \"No\").then(False).otherwise(True).keep_name()]\n",
    ")\n",
    "\n",
    "# print out datatype of column post find and replace operation\n",
    "rdf.select(\"change\").dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYS-Mkl1tD8t"
   },
   "source": [
    "### Saving our RemoteLazyFrame and disconnecting\n",
    "\n",
    "Our dataframe is all clean and ready for the next step: data analysis/ visualization. Data scientist #1 is going to be reassigned to another task. They will save their cleaned RemoteLazyFrame and make a note of the identifier to share with data scientist #2.\n",
    "\n",
    "We need to perform `collect()` before saving or getting an identifier for our RemoteLazyFrame since the `save` method and `identifier` attribute are only available for FetchableLazyFrames.\n",
    "\n",
    ">Note, the data owner must have set the `savable` option to `True` when uploading the dataframe for this operation to be possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "DWu6ToX53bm9",
    "outputId": "3063c7ae-df03-4b74-d7a3-e2ceffc56083"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'49b66d7a-6c80-45fb-8278-9992c91f8666'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.collect().save()\n",
    "saved_identifier = rdf.collect().identifier\n",
    "saved_identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgkiBinG6DJ2"
   },
   "source": [
    "They can now close their connection to the BastionLab server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoiADM1W6OC_"
   },
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
