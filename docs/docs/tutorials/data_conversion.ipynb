{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"colab_button\">\n",
    "  <h1>Data conversion</h1>\n",
    "  <a target=\"https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.7/docs/docs/tutorials/data_conversion.ipynb\" href=\"LINK COLAB\"> \n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "</div>\n",
    "\n",
    "__________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for data scientists to use BastionLab from data exploration to deep learning training and machine learning model fitting, it's important that they are able to convert remote data to their respective representations.\n",
    "\n",
    "This tutorial introduces how you can convert a `RemoteDataFrame` to `RemoteTensor`, using a `RemoteArray` intermediary step, and use them for your deep learning model training. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "___________________________________________\n",
    "\n",
    "### Installation and dataset\n",
    "\n",
    "In order to run this notebook, we need to:\n",
    "- Have [Python3.7](https://www.python.org/downloads/) (or greater) and [Python Pip](https://pypi.org/project/pip/) installed\n",
    "- Install [BastionLab](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/)\n",
    "- Install PyTorch [1.13.1](https://pypi.org/project/torch/)\n",
    "- Download [the dataset](https://www.kaggle.com/competitions/titanic) we will be using in this tutorial.\n",
    "\n",
    "We'll do so by running the code block below. \n",
    "\n",
    ">If you are running this notebook on your machine instead of [Google Colab](https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.6/docs/docs/tutorials/data_conversion.ipynb), you can see our [Installation page](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/) to find the installation method that best suits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip packages\n",
    "!pip install bastionlab\n",
    "!pip install bastionlab_server\n",
    "!pip install torch\n",
    "\n",
    "# download the dataset\n",
    "!wget 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is based on the [Titanic dataset](https://www.kaggle.com/c/titanic), one of the most popular ressource used for understanding machine learning, which contains information relating to the passengers aboard the Titanic. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch and connect to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch bastionlab_server test package\n",
    "import bastionlab_server\n",
    "\n",
    "srv = bastionlab_server.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Note that the bastionlab_server package we install here was created for testing purposes. You can also install BastionLab server using our Docker image or from source (especially for non-test purposes). Check out our [Installation Tutorial](../getting-started/installation.md) for more details.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbamponsem/base/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# connect to the server\n",
    "from bastionlab import Connection\n",
    "\n",
    "connection = Connection(\"localhost\")\n",
    "client = connection.client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the dataframe to the server\n",
    "\n",
    "We'll quickly upload the dataset to the server with an open safety policy, since setting up BastionLab is not the focus of this tutorial. It will allows us to demonstrate features without having to approve any data access requests. *You can check out how to define a privacy policy [here](https://bastionlab.readthedocs.io/en/latest/docs/tutorials/defining_policy_privacy/).* \n",
    "\n",
    "We'll also limit the size of the dataset sent to the server, with Polar's `df.limit()` method, to run this tutorial faster and use less ressources - since we are only performing data conversion and not full on data exploration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchableLazyFrame(identifier=3354b658-09a1-48c7-827d-4fccf9797a0b)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "from bastionlab.polars.policy import Policy, TrueRule, Log\n",
    "\n",
    "df = pl.read_csv(\"titanic.csv\")\n",
    "policy = Policy(safe_zone=TrueRule(), unsafe_handling=Log(), savable=False)\n",
    "rdf = client.polars.send_df(df.limit(100), policy=policy)\n",
    "\n",
    "rdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert `RemoteDataFrame` to `RemoteArray`\n",
    "----\n",
    "\n",
    "To convert BastionLab's main data exploration object, the `RemoteDataFrame`, to it's AI training's main object `RemoteTensor`, we'll need to go through an intermediary step: the `RemoteArray`. \n",
    "\n",
    "Since [NumPy](https://numpy.org/) library's `array`s are commonly used in machine learning training, we decided to make our user interface and experience similar. What we'll show in this tutorial will be as straightforward as fitting a [Scikit-learn](https://scikit-learn.org/stable/) `LinearRegression` model on a NumPy `array`.\n",
    "```python\n",
    "\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    lr.fit(array)\n",
    "\n",
    "```\n",
    "\n",
    "Except, in BastionLab, `array` will be `RemoteArray`, which are pointers to a `RemoteDataFrame`. When `to_tensor()` will be called, they'll convert the `RemoteDataFrame` to a `RemoteTensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "no_execute"
    ]
   },
   "outputs": [
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.ABORTED\n\tdetails = \"DataFrame with str columns cannot be converted directly to RemoteArray. Please tokenize strings first\"\n\tdebug_error_string = \"{\"created\":\"@1675413761.568726972\",\"description\":\"Error received from peer ipv4:127.0.0.1:50056\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":966,\"grpc_message\":\"DataFrame with str columns cannot be converted directly to RemoteArray. Please tokenize strings first\",\"grpc_status\":10}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Converting a RemoteDataFrame to a RemoteArray\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rdf\u001b[39m.\u001b[39;49mto_array()\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/polars/remote_polars.py:1011\u001b[0m, in \u001b[0;36mFetchableLazyFrame.to_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m \u001b[39mConverts a FetchableLazyFrame into a RemoteArray\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \n\u001b[1;32m   1007\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[39m    RemoteArray\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m client \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_meta\u001b[39m.\u001b[39m_polars_client\u001b[39m.\u001b[39mclient\n\u001b[0;32m-> 1011\u001b[0m res \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49m_converter\u001b[39m.\u001b[39;49m_stub\u001b[39m.\u001b[39;49mConvToArray(\n\u001b[1;32m   1012\u001b[0m     PbRemoteDataFrame(identifier\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_identifier)\n\u001b[1;32m   1013\u001b[0m )\n\u001b[1;32m   1014\u001b[0m \u001b[39mreturn\u001b[39;00m RemoteArray(client, res\u001b[39m.\u001b[39midentifier)\n",
      "File \u001b[0;32m~/base/lib/python3.8/site-packages/grpc/_channel.py:946\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    938\u001b[0m              request,\n\u001b[1;32m    939\u001b[0m              timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m              wait_for_ready\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    943\u001b[0m              compression\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    944\u001b[0m     state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    945\u001b[0m                                   wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0m     \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/base/lib/python3.8/site-packages/grpc/_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[39mreturn\u001b[39;00m state\u001b[39m.\u001b[39mresponse\n\u001b[1;32m    848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.ABORTED\n\tdetails = \"DataFrame with str columns cannot be converted directly to RemoteArray. Please tokenize strings first\"\n\tdebug_error_string = \"{\"created\":\"@1675413761.568726972\",\"description\":\"Error received from peer ipv4:127.0.0.1:50056\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":966,\"grpc_message\":\"DataFrame with str columns cannot be converted directly to RemoteArray. Please tokenize strings first\",\"grpc_status\":10}\"\n>"
     ]
    }
   ],
   "source": [
    "# Converting a RemoteDataFrame to a RemoteArray\n",
    "rdf.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh but wait. It didn't work! We got an error message: _`TypeError: DataFrame with str columns cannot be converted directly to RemoteArray. Please tokenize strings first`_.\n",
    "\n",
    "This means we need to make sure our `RemoteDataFrame` only has numerical fields (_ints, floats_) before we convert it into a `RemoteArray`. This makes sense because tensors only accept numerical values, and arrays are here to prepare that next conversion step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchableLazyFrame(identifier=14c440b4-705f-4660-978d-c44effbf3731)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use Polar's pl.col() method to convert all values to numerical ones\n",
    "rdf = rdf.select(pl.col([pl.Float64, pl.Float32, pl.Int64, pl.Int32])).collect()\n",
    "\n",
    "rdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to convert our `RemoteDataFrame` once more to a `RemoteArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "no_execute"
    ]
   },
   "outputs": [
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.ABORTED\n\tdetails = \"DataTypes for all columns should be the same\"\n\tdebug_error_string = \"{\"created\":\"@1675413901.986313646\",\"description\":\"Error received from peer ipv4:127.0.0.1:50056\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":966,\"grpc_message\":\"DataTypes for all columns should be the same\",\"grpc_status\":10}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Converting RemoteDataFrame to RemoteArray\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rdf\u001b[39m.\u001b[39;49mto_array()\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/polars/remote_polars.py:1011\u001b[0m, in \u001b[0;36mFetchableLazyFrame.to_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m \u001b[39mConverts a FetchableLazyFrame into a RemoteArray\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \n\u001b[1;32m   1007\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[39m    RemoteArray\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m client \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_meta\u001b[39m.\u001b[39m_polars_client\u001b[39m.\u001b[39mclient\n\u001b[0;32m-> 1011\u001b[0m res \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49m_converter\u001b[39m.\u001b[39;49m_stub\u001b[39m.\u001b[39;49mConvToArray(\n\u001b[1;32m   1012\u001b[0m     PbRemoteDataFrame(identifier\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_identifier)\n\u001b[1;32m   1013\u001b[0m )\n\u001b[1;32m   1014\u001b[0m \u001b[39mreturn\u001b[39;00m RemoteArray(client, res\u001b[39m.\u001b[39midentifier)\n",
      "File \u001b[0;32m~/base/lib/python3.8/site-packages/grpc/_channel.py:946\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    938\u001b[0m              request,\n\u001b[1;32m    939\u001b[0m              timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m              wait_for_ready\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    943\u001b[0m              compression\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    944\u001b[0m     state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    945\u001b[0m                                   wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0m     \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/base/lib/python3.8/site-packages/grpc/_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[39mreturn\u001b[39;00m state\u001b[39m.\u001b[39mresponse\n\u001b[1;32m    848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.ABORTED\n\tdetails = \"DataTypes for all columns should be the same\"\n\tdebug_error_string = \"{\"created\":\"@1675413901.986313646\",\"description\":\"Error received from peer ipv4:127.0.0.1:50056\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":966,\"grpc_message\":\"DataTypes for all columns should be the same\",\"grpc_status\":10}\"\n>"
     ]
    }
   ],
   "source": [
    "# Converting RemoteDataFrame to RemoteArray\n",
    "rdf.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, our `to_array()` method gives out an error! _`TypeError: DataTypes for all columns should be the same`_.\n",
    "\n",
    "This means we need to cast all our columns first before converting them into an array. Here, we'll choose `Float64` to capture all numerical values.\n",
    "\n",
    "> *It is very important that we cast all our columns into a single datatype to make our `RemoteArray` compatible with other libraries and machine learning applications - as arrays are supposed to be a collection of objects of the same type.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchableLazyFrame(identifier=be18403f-7bec-4a73-ba12-9ece528497ec)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting all values of the RemoteDataFrame to Float64\n",
    "rdf = rdf.select(pl.all().cast(pl.Float64)).collect()\n",
    "\n",
    "rdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try again to convert `RemoteDataFrame` into `RemoteArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemoteArray(identifier=923b1f40-7e0f-4857-ba2d-aab315ef3e89)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting RemoteDataFrame to RemoteArray\n",
    "rdf.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a success! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert `RemoteArray` to `RemoteTensor`\n",
    "____________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now that we converted our `RemoteDataFrame` to a `Remote Array`, we'll convert the `RemoteArray` to a `RemoteTensor` to be able to train our model. This shouldn't run into problems, since the `RemoteArray` step would have already taken care of eventual conversion issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts `RemoteArray` into `RemoteTensor`\n",
    "# (using the middle step of converting to RemoteArray)\n",
    "remote_tensor = rdf.to_array().to_tensor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `RemoteTensor` has been created, we can go ahead and print its available properties, which are `dtype` and `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RemoteTensor(identifier=8e90ece5-11b1-4c88-b877-0e9c9b4152b8, dtype=torch.float64, shape=torch.Size([100, 7]))\n"
     ]
    }
   ],
   "source": [
    "print(remote_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to only show you those two properties (the type of the tensor and its shape) to protect the privacy of the data - but still give you the vital information you need to train your model. \n",
    "\n",
    ">*You can refer to our [Covid 19 deep learning](https://github.com/mithril-security/bastionlab/blob/master/docs/docs/how-to-guides/covid_19_deep_learning_cleaning.ipynb) how-to-guide to see how we use `RemoteTensor`s in training a PyTorch Linear Regression model.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the `dtype` of `RemoteTensor`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the only method you can use on `RemoteTensor`, because we need to limit access to guarantee the privacy of the data stored. \n",
    "\n",
    "We'll use `to()`, just like with a regular torch tensor, to change the `dtype` of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemoteTensor(identifier=8e90ece5-11b1-4c88-b877-0e9c9b4152b8, dtype=torch.int64, shape=torch.Size([100, 7]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Using the to() method to update the dtype of the RemoteTensor\n",
    "remote_tensor.to(torch.int64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dtype` for the RemoteTensor has been updated to `int64`!\n",
    "\n",
    "You now know how to convert RemoteDataframe to RemoteTensor. \n",
    "\n",
    "All that's left to do now is to close your connection to the server and stop the server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()\n",
    "bastionlab_server.stop(srv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfb725626286d8c8fc5334ffe77697f720dc23e64d3046271825a5556b528e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
