{
 "cells": [
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bastionlab import Identity\n",
    "\n",
    "# Create `Identity` for Data owner.\n",
    "data_owner = Identity.create(\"data_owner\")"
=======
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"colab_button\">\n",
    "  <h1>Data conversion</h1>\n",
    "  <a target=\"https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.7/docs/docs/tutorials/data_conversion.ipynb\" href=\"LINK COLAB\"> \n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "</div>\n",
    "\n",
    "__________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for data scientists to use BastionLab from data exploration to deep learning training and machine learning model fitting, it's important that they are able to convert remote data to their respective representations.\n",
    "\n",
    "This tutorial introduces how you can convert a `RemoteDataFrame` to `RemoteTensor`, using a `RemoteArray` intermediary step, and use them for your deep learning model training. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "___________________________________________\n",
    "\n",
    "### Installation and dataset\n",
    "\n",
    "In order to run this notebook, we need to:\n",
    "- Have [Python3.7](https://www.python.org/downloads/) (or greater) and [Python Pip](https://pypi.org/project/pip/) installed\n",
    "- Install [BastionLab](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/)\n",
    "- Install PyTorch [1.13.1](https://pypi.org/project/torch/)\n",
    "- Download [the dataset](https://www.kaggle.com/competitions/titanic) we will be using in this tutorial.\n",
    "\n",
    "We'll do so by running the code block below. \n",
    "\n",
    ">If you are running this notebook on your machine instead of [Google Colab](https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.6/docs/docs/tutorials/data_conversion.ipynb), you can see our [Installation page](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/) to find the installation method that best suits your needs."
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
=======
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip packages\n",
    "!pip install bastionlab\n",
    "!pip install bastionlab_server\n",
    "!pip install torch\n",
    "\n",
    "# download the dataset\n",
>>>>>>> master
    "!wget 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python datagen.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
    "!unzip smsspamcollection.zip"
=======
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is based on the [Titanic dataset](https://www.kaggle.com/c/titanic), one of the most popular ressource used for understanding machine learning, which contains information relating to the passengers aboard the Titanic. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch and connect to the server"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==0.13.2"
=======
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch bastionlab_server test package\n",
    "import bastionlab_server\n",
    "\n",
    "srv = bastionlab_server.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Note that the bastionlab_server package we install here was created for testing purposes. You can also install BastionLab server using our Docker image or from source (especially for non-test purposes). Check out our [Installation Tutorial](../getting-started/installation.md) for more details.*"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbamponsem/base/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
<<<<<<< HEAD
    },
    {
     "ename": "AttributeError",
     "evalue": "'BastionLabPolars' object has no attribute 'client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m connection \u001b[39m=\u001b[39m Connection(\u001b[39m\"\u001b[39m\u001b[39mlocalhost\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m policy \u001b[39m=\u001b[39m Policy(safe_zone\u001b[39m=\u001b[39mAggregation(min_agg_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m), unsafe_handling\u001b[39m=\u001b[39mLog())\n\u001b[0;32m---> 22\u001b[0m rdf \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mpolars\u001b[39m.\u001b[39;49msend_df(df, policy\u001b[39m=\u001b[39;49mpolicy, sanitized_columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     24\u001b[0m ratio \u001b[39m=\u001b[39m \u001b[39m0.25\u001b[39m\n\u001b[1;32m     25\u001b[0m train_rdf, test_rdf \u001b[39m=\u001b[39m train_test_split(rdf, test_size\u001b[39m=\u001b[39mratio, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/polars/client.py:85\u001b[0m, in \u001b[0;36mBastionLabPolars.send_df\u001b[0;34m(self, df, policy, sanitized_columns)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mThis method is used to send `polars.internals.dataframe.frame.DataFrame` to the BastionLab server.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39m>>> connection.client.polars.send_df(df, policy=policy, sanitized_columns=[\"Name\"])\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mremote_polars\u001b[39;00m \u001b[39mimport\u001b[39;00m FetchableLazyFrame\n\u001b[0;32m---> 85\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39mrefresh_session_if_needed()\n\u001b[1;32m     87\u001b[0m res \u001b[39m=\u001b[39m GRPCException\u001b[39m.\u001b[39mmap_error(\n\u001b[1;32m     88\u001b[0m     \u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstub\u001b[39m.\u001b[39mSendDataFrame(\n\u001b[1;32m     89\u001b[0m         serialize_dataframe(df, policy, sanitized_columns)\n\u001b[1;32m     90\u001b[0m     )\n\u001b[1;32m     91\u001b[0m )\n\u001b[1;32m     92\u001b[0m \u001b[39mreturn\u001b[39;00m FetchableLazyFrame\u001b[39m.\u001b[39m_from_reference(\u001b[39mself\u001b[39m, res)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BastionLabPolars' object has no attribute 'client'"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from bastionlab.polars.policy import Policy, Aggregation, Log\n",
    "from bastionlab.polars import train_test_split\n",
    "import polars as pl\n",
    "from bastionlab import Connection\n",
    "\n",
    "file_path = \"./SMSSpamCollection\"\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "with open(file_path) as f:\n",
    "    for line in f.readlines():\n",
    "        split = line.split(\"\\t\")\n",
    "        labels.append(1 if split[0] == \"spam\" else 0)\n",
    "        texts.append(split[1])\n",
    "df = pl.DataFrame({\"label\": labels, \"text\": texts})\n",
    "\n",
    "connection = Connection(\"localhost\")\n",
    "\n",
    "\n",
    "policy = Policy(safe_zone=Aggregation(min_agg_size=10), unsafe_handling=Log())\n",
    "rdf = connection.client.polars.send_df(df, policy=policy, sanitized_columns=[\"text\"])\n",
    "\n",
    "ratio = 0.25\n",
    "train_rdf, test_rdf = train_test_split(rdf, test_size=ratio, shuffle=True)\n",
    "\n",
    "tokenizer = Tokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokenizer.enable_truncation(max_length=32)\n",
    "tokenizer.enable_padding(length=32)\n",
    "\n",
    "train_rds = (\n",
    "    train_rdf.convert([\"text\"], tokenizer.to_str())\n",
    "    .collect()\n",
    "    .to_dataset([\"text_ids\", \"text_mask\"], \"label\")\n",
    ")\n",
    "test_rds = (\n",
    "    test_rdf.convert([\"text\"], tokenizer.to_str())\n",
    "    .collect()\n",
    "    .to_dataset([\"text_ids\", \"text_mask\"], \"label\")\n",
    ")\n",
    "\n",
    "\n",
    "train_rds._set_test_dataset(test_rds.train_dataset_ref)\n",
    "test_rds.set_train_dataset(train_dataset=train_rds.train_dataset_ref)"
=======
    }
   ],
   "source": [
    "# connect to the server\n",
    "from bastionlab import Connection\n",
    "\n",
    "connection = Connection(\"localhost\")\n",
    "client = connection.client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the dataframe to the server\n",
    "\n",
    "We'll quickly upload the dataset to the server with an open safety policy, since setting up BastionLab is not the focus of this tutorial. It will allows us to demonstrate features without having to approve any data access requests. *You can check out how to define a privacy policy [here](https://bastionlab.readthedocs.io/en/latest/docs/tutorials/defining_policy_privacy/).* \n",
    "\n",
    "We'll also limit the size of the dataset sent to the server, with Polar's `df.limit()` method, to run this tutorial faster and use less ressources - since we are only performing data conversion and not full on data exploration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchableLazyFrame(identifier=3354b658-09a1-48c7-827d-4fccf9797a0b)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "from bastionlab.polars.policy import Policy, TrueRule, Log\n",
    "\n",
    "df = pl.read_csv(\"titanic.csv\")\n",
    "policy = Policy(safe_zone=TrueRule(), unsafe_handling=Log(), savable=False)\n",
    "rdf = client.polars.send_df(df.limit(100), policy=policy)\n",
    "\n",
    "rdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert `RemoteDataFrame` to `RemoteArray`\n",
    "----\n",
    "\n",
    "To convert BastionLab's main data exploration object, the `RemoteDataFrame`, to it's AI training's main object `RemoteTensor`, we'll need to go through an intermediary step: the `RemoteArray`. \n",
    "\n",
    "Since [NumPy](https://numpy.org/) library's `array`s are commonly used in machine learning training, we decided to make our user interface and experience similar. What we'll show in this tutorial will be as straightforward as fitting a [Scikit-learn](https://scikit-learn.org/stable/) `LinearRegression` model on a NumPy `array`.\n",
    "```python\n",
    "\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    lr.fit(array)\n",
    "\n",
    "```\n",
    "\n",
    "Except, in BastionLab, `array` will be `RemoteArray`, which are pointers to a `RemoteDataFrame`. When `to_tensor()` will be called, they'll convert the `RemoteDataFrame` to a `RemoteTensor`."
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers"
=======
   "execution_count": 20,
   "metadata": {
    "tags": [
     "no_execute"
    ]
   },
   "outputs": [
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.ABORTED\n\tdetails = \"DataFrame with str columns cannot be converted directly to RemoteArray. Please tokenize strings first\"\n\tdebug_error_string = \"{\"created\":\"@1675413761.568726972\",\"description\":\"Error received from peer ipv4:127.0.0.1:50056\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":966,\"grpc_message\":\"DataFrame with str columns cannot be converted directly to RemoteArray. Please tokenize strings first\",\"grpc_status\":10}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Converting a RemoteDataFrame to a RemoteArray\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rdf\u001b[39m.\u001b[39;49mto_array()\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/polars/remote_polars.py:1011\u001b[0m, in \u001b[0;36mFetchableLazyFrame.to_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m \u001b[39mConverts a FetchableLazyFrame into a RemoteArray\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \n\u001b[1;32m   1007\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[39m    RemoteArray\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m client \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_meta\u001b[39m.\u001b[39m_polars_client\u001b[39m.\u001b[39mclient\n\u001b[0;32m-> 1011\u001b[0m res \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49m_converter\u001b[39m.\u001b[39;49m_stub\u001b[39m.\u001b[39;49mConvToArray(\n\u001b[1;32m   1012\u001b[0m     PbRemoteDataFrame(identifier\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_identifier)\n\u001b[1;32m   1013\u001b[0m )\n\u001b[1;32m   1014\u001b[0m \u001b[39mreturn\u001b[39;00m RemoteArray(client, res\u001b[39m.\u001b[39midentifier)\n",
      "File \u001b[0;32m~/base/lib/python3.8/site-packages/grpc/_channel.py:946\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    938\u001b[0m              request,\n\u001b[1;32m    939\u001b[0m              timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m              wait_for_ready\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    943\u001b[0m              compression\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    944\u001b[0m     state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    945\u001b[0m                                   wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0m     \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/base/lib/python3.8/site-packages/grpc/_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[39mreturn\u001b[39;00m state\u001b[39m.\u001b[39mresponse\n\u001b[1;32m    848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.ABORTED\n\tdetails = \"DataFrame with str columns cannot be converted directly to RemoteArray. Please tokenize strings first\"\n\tdebug_error_string = \"{\"created\":\"@1675413761.568726972\",\"description\":\"Error received from peer ipv4:127.0.0.1:50056\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":966,\"grpc_message\":\"DataFrame with str columns cannot be converted directly to RemoteArray. Please tokenize strings first\",\"grpc_status\":10}\"\n>"
     ]
    }
   ],
   "source": [
    "# Converting a RemoteDataFrame to a RemoteArray\n",
    "rdf.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh but wait. It didn't work! We got an error message: _`TypeError: DataFrame with str columns cannot be converted directly to RemoteArray. Please tokenize strings first`_.\n",
    "\n",
    "This means we need to make sure our `RemoteDataFrame` only has numerical fields (_ints, floats_) before we convert it into a `RemoteArray`. This makes sense because tensors only accept numerical values, and arrays are here to prepare that next conversion step."
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchableLazyFrame(identifier=14c440b4-705f-4660-978d-c44effbf3731)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use Polar's pl.col() method to convert all values to numerical ones\n",
    "rdf = rdf.select(pl.col([pl.Float64, pl.Float32, pl.Int64, pl.Int32])).collect()\n",
    "\n",
    "rdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to convert our `RemoteDataFrame` once more to a `RemoteArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "no_execute"
    ]
   },
   "outputs": [
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.ABORTED\n\tdetails = \"DataTypes for all columns should be the same\"\n\tdebug_error_string = \"{\"created\":\"@1675413901.986313646\",\"description\":\"Error received from peer ipv4:127.0.0.1:50056\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":966,\"grpc_message\":\"DataTypes for all columns should be the same\",\"grpc_status\":10}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Converting RemoteDataFrame to RemoteArray\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rdf\u001b[39m.\u001b[39;49mto_array()\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/polars/remote_polars.py:1011\u001b[0m, in \u001b[0;36mFetchableLazyFrame.to_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m \u001b[39mConverts a FetchableLazyFrame into a RemoteArray\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \n\u001b[1;32m   1007\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[39m    RemoteArray\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m client \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_meta\u001b[39m.\u001b[39m_polars_client\u001b[39m.\u001b[39mclient\n\u001b[0;32m-> 1011\u001b[0m res \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49m_converter\u001b[39m.\u001b[39;49m_stub\u001b[39m.\u001b[39;49mConvToArray(\n\u001b[1;32m   1012\u001b[0m     PbRemoteDataFrame(identifier\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_identifier)\n\u001b[1;32m   1013\u001b[0m )\n\u001b[1;32m   1014\u001b[0m \u001b[39mreturn\u001b[39;00m RemoteArray(client, res\u001b[39m.\u001b[39midentifier)\n",
      "File \u001b[0;32m~/base/lib/python3.8/site-packages/grpc/_channel.py:946\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    938\u001b[0m              request,\n\u001b[1;32m    939\u001b[0m              timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m              wait_for_ready\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    943\u001b[0m              compression\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    944\u001b[0m     state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    945\u001b[0m                                   wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0m     \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/base/lib/python3.8/site-packages/grpc/_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[39mreturn\u001b[39;00m state\u001b[39m.\u001b[39mresponse\n\u001b[1;32m    848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.ABORTED\n\tdetails = \"DataTypes for all columns should be the same\"\n\tdebug_error_string = \"{\"created\":\"@1675413901.986313646\",\"description\":\"Error received from peer ipv4:127.0.0.1:50056\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":966,\"grpc_message\":\"DataTypes for all columns should be the same\",\"grpc_status\":10}\"\n>"
>>>>>>> master
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "from bastionlab.torch.utils import MultipleOutputWrapper\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    torchscript=True,\n",
    ")\n",
    "model = MultipleOutputWrapper(model, 0)"
=======
    "# Converting RemoteDataFrame to RemoteArray\n",
    "rdf.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, our `to_array()` method gives out an error! _`TypeError: DataTypes for all columns should be the same`_.\n",
    "\n",
    "This means we need to cast all our columns first before converting them into an array. Here, we'll choose `Float64` to capture all numerical values.\n",
    "\n",
    "> *It is very important that we cast all our columns into a single datatype to make our `RemoteArray` compatible with other libraries and machine learning applications - as arrays are supposed to be a collection of objects of the same type.*"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<bastionlab.torch.learner.RemoteDataset object at 0x7fddc8777be0>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 8,
=======
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchableLazyFrame(identifier=be18403f-7bec-4a73-ba12-9ece528497ec)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting all values of the RemoteDataFrame to Float64\n",
    "rdf = rdf.select(pl.all().cast(pl.Float64)).collect()\n",
    "\n",
    "rdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try again to convert `RemoteDataFrame` into `RemoteArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemoteArray(identifier=923b1f40-7e0f-4857-ba2d-aab315ef3e89)"
      ]
     },
     "execution_count": 6,
>>>>>>> master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "remote_datasets = connection.client.torch.list_remote_datasets()\n",
    "print(remote_datasets)\n",
    "\n",
    "remote_datasets[0].trace_input"
=======
    "# Converting RemoteDataFrame to RemoteArray\n",
    "rdf.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a success! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert `RemoteArray` to `RemoteTensor`\n",
    "____________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now that we converted our `RemoteDataFrame` to a `Remote Array`, we'll convert the `RemoteArray` to a `RemoteTensor` to be able to train our model. This shouldn't run into problems, since the `RemoteArray` step would have already taken care of eventual conversion issues.\n"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending DistilBERT: 100%|████████████████████| 268M/268M [00:05<00:00, 46.9MB/s] \n"
=======
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts `RemoteArray` into `RemoteTensor`\n",
    "# (using the middle step of converting to RemoteArray)\n",
    "remote_tensor = rdf.to_array().to_tensor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `RemoteTensor` has been created, we can go ahead and print its available properties, which are `dtype` and `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RemoteTensor(identifier=8e90ece5-11b1-4c88-b877-0e9c9b4152b8, dtype=torch.float64, shape=torch.Size([100, 7]))\n"
>>>>>>> master
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "from bastionlab.torch.optimizer_config import Adam\n",
    "\n",
    "remote_learner = connection.client.torch.RemoteLearner(\n",
    "    model,\n",
    "    remote_datasets[0],\n",
    "    max_batch_size=2,\n",
    "    loss=\"cross_entropy\",\n",
    "    optimizer=Adam(lr=5e-5),\n",
    "    model_name=\"DistilBERT\",\n",
    "    expand=False,\n",
    ")"
=======
    "print(remote_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to only show you those two properties (the type of the tensor and its shape) to protect the privacy of the data - but still give you the vital information you need to train your model. \n",
    "\n",
    ">*You can refer to our [Covid 19 deep learning](https://github.com/mithril-security/bastionlab/blob/master/docs/docs/how-to-guides/covid_19_deep_learning_cleaning.ipynb) how-to-guide to see how we use `RemoteTensor`s in training a PyTorch Linear Regression model.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the `dtype` of `RemoteTensor`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the only method you can use on `RemoteTensor`, because we need to limit access to guarantee the privacy of the data stored. \n",
    "\n",
    "We'll use `to()`, just like with a regular torch tensor, to change the `dtype` of the tensor."
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 - train:   0%|                    | 5/2090 [00:12<1:25:39,  2.46s/batch, cross_entropy=0.0000 (+/- 3729.0254)] "
     ]
    },
    {
     "ename": "GRPCException",
     "evalue": "Connection to the gRPC server failed: code=StatusCode.UNAVAILABLE message=Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/errors.py:70\u001b[0m, in \u001b[0;36mGRPCException.map_error\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mreturn\u001b[39;00m f()\n\u001b[1;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m _InactiveRpcError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/torch/client.py:198\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest\u001b[39m(\u001b[39mself\u001b[39m, config: TestConfig) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Reference:\n\u001b[1;32m    196\u001b[0m     \u001b[39m\"\"\"Tests a dataset on a model according to `config` on the BastionAI server.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[0;32m--> 198\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m        config: Testing configuration that specifies the model, dataset and hyperparameters.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mrefresh_session_if_needed()\n",
      "File \u001b[0;32m~/base/lib/python3.8/site-packages/grpc/_channel.py:946\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    944\u001b[0m state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    945\u001b[0m                               wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0m \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/base/lib/python3.8/site-packages/grpc/_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"Connection reset by peer\"\n\tdebug_error_string = \"{\"created\":\"@1672743111.470227510\",\"description\":\"Error received from peer ipv4:127.0.0.1:50056\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":966,\"grpc_message\":\"Connection reset by peer\",\"grpc_status\":14}\"\n>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mGRPCException\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/kbamponsem/Projects/bastionlab/docs/docs/tutorials/data_conversion.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kbamponsem/Projects/bastionlab/docs/docs/tutorials/data_conversion.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m remote_learner\u001b[39m.\u001b[39;49mfit(nb_epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, eps\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/torch/learner.py:467\u001b[0m, in \u001b[0;36mRemoteLearner.fit\u001b[0;34m(self, nb_epochs, eps, batch_size, max_grad_norm, lr, metric_eps, timeout, poll_delay, per_n_epochs_checkpoint, per_n_steps_checkpoint, resume)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39m\"\"\"Fits the uploaded model to the training dataset with given hyperparameters.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \n\u001b[1;32m    443\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39m    poll_delay: Delay in seconds between two polling requests for the loss.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m run \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mtrain(\n\u001b[1;32m    455\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_config(\n\u001b[1;32m    456\u001b[0m         nb_epochs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    465\u001b[0m     )\n\u001b[1;32m    466\u001b[0m )\n\u001b[0;32m--> 467\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll_metric(\n\u001b[1;32m    468\u001b[0m     run,\n\u001b[1;32m    469\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss,\n\u001b[1;32m    470\u001b[0m     train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    471\u001b[0m     timeout\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(timeout \u001b[39m/\u001b[39;49m poll_delay),\n\u001b[1;32m    472\u001b[0m     poll_delay\u001b[39m=\u001b[39;49mpoll_delay,\n\u001b[1;32m    473\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/torch/learner.py:392\u001b[0m, in \u001b[0;36mRemoteLearner._poll_metric\u001b[0;34m(self, run, name, train, timeout, poll_delay)\u001b[0m\n\u001b[1;32m    390\u001b[0m prev_batch \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mbatch\n\u001b[1;32m    391\u001b[0m prev_epoch \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mepoch\n\u001b[0;32m--> 392\u001b[0m metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mget_metric(run)\n\u001b[1;32m    394\u001b[0m \u001b[39m# Handle end of training\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m metric\u001b[39m.\u001b[39mbatch \u001b[39m==\u001b[39m prev_batch \u001b[39mand\u001b[39;00m metric\u001b[39m.\u001b[39mepoch \u001b[39m==\u001b[39m prev_epoch:\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/torch/client.py:198\u001b[0m, in \u001b[0;36mget_metric\u001b[0;34m(self, run)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest\u001b[39m(\u001b[39mself\u001b[39m, config: TestConfig) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Reference:\n\u001b[1;32m    196\u001b[0m     \u001b[39m\"\"\"Tests a dataset on a model according to `config` on the BastionAI server.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[0;32m--> 198\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m        config: Testing configuration that specifies the model, dataset and hyperparameters.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mrefresh_session_if_needed()\n\u001b[1;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m GRPCException\u001b[39m.\u001b[39mmap_error(\u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstub\u001b[39m.\u001b[39mTest(config))\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/errors.py:72\u001b[0m, in \u001b[0;36mGRPCException.map_error\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m f()\n\u001b[1;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m _InactiveRpcError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mraise\u001b[39;00m GRPCException(e)\n\u001b[1;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m _MultiThreadedRendezvous \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     74\u001b[0m     \u001b[39mraise\u001b[39;00m GRPCException(e)\n",
      "\u001b[0;31mGRPCException\u001b[0m: Connection to the gRPC server failed: code=StatusCode.UNAVAILABLE message=Connection reset by peer"
     ]
    }
   ],
   "source": [
    "remote_learner.fit(nb_epochs=2, eps=None)"
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemoteTensor(identifier=8e90ece5-11b1-4c88-b877-0e9c9b4152b8, dtype=torch.int64, shape=torch.Size([100, 7]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Using the to() method to update the dtype of the RemoteTensor\n",
    "remote_tensor.to(torch.int64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dtype` for the RemoteTensor has been updated to `int64`!\n",
    "\n",
    "You now know how to convert RemoteDataframe to RemoteTensor. \n",
    "\n",
    "All that's left to do now is to close your connection to the server and stop the server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()\n",
    "bastionlab_server.stop(srv)"
>>>>>>> master
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfb725626286d8c8fc5334ffe77697f720dc23e64d3046271825a5556b528e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
