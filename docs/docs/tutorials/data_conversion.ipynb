{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bastionlab import Identity\n",
    "\n",
    "# Create `Identity` for Data owner.\n",
    "data_owner = Identity.create(\"data_owner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python datagen.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
    "!unzip smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==0.13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbamponsem/base/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BastionLabPolars' object has no attribute 'client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m connection \u001b[39m=\u001b[39m Connection(\u001b[39m\"\u001b[39m\u001b[39mlocalhost\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m policy \u001b[39m=\u001b[39m Policy(safe_zone\u001b[39m=\u001b[39mAggregation(min_agg_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m), unsafe_handling\u001b[39m=\u001b[39mLog())\n\u001b[0;32m---> 22\u001b[0m rdf \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mpolars\u001b[39m.\u001b[39;49msend_df(df, policy\u001b[39m=\u001b[39;49mpolicy, sanitized_columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     24\u001b[0m ratio \u001b[39m=\u001b[39m \u001b[39m0.25\u001b[39m\n\u001b[1;32m     25\u001b[0m train_rdf, test_rdf \u001b[39m=\u001b[39m train_test_split(rdf, test_size\u001b[39m=\u001b[39mratio, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/polars/client.py:85\u001b[0m, in \u001b[0;36mBastionLabPolars.send_df\u001b[0;34m(self, df, policy, sanitized_columns)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mThis method is used to send `polars.internals.dataframe.frame.DataFrame` to the BastionLab server.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39m>>> connection.client.polars.send_df(df, policy=policy, sanitized_columns=[\"Name\"])\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mremote_polars\u001b[39;00m \u001b[39mimport\u001b[39;00m FetchableLazyFrame\n\u001b[0;32m---> 85\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39mrefresh_session_if_needed()\n\u001b[1;32m     87\u001b[0m res \u001b[39m=\u001b[39m GRPCException\u001b[39m.\u001b[39mmap_error(\n\u001b[1;32m     88\u001b[0m     \u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstub\u001b[39m.\u001b[39mSendDataFrame(\n\u001b[1;32m     89\u001b[0m         serialize_dataframe(df, policy, sanitized_columns)\n\u001b[1;32m     90\u001b[0m     )\n\u001b[1;32m     91\u001b[0m )\n\u001b[1;32m     92\u001b[0m \u001b[39mreturn\u001b[39;00m FetchableLazyFrame\u001b[39m.\u001b[39m_from_reference(\u001b[39mself\u001b[39m, res)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BastionLabPolars' object has no attribute 'client'"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from bastionlab.polars.policy import Policy, Aggregation, Log\n",
    "from bastionlab.polars import train_test_split\n",
    "import polars as pl\n",
    "from bastionlab import Connection\n",
    "\n",
    "file_path = \"./SMSSpamCollection\"\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "with open(file_path) as f:\n",
    "    for line in f.readlines():\n",
    "        split = line.split(\"\\t\")\n",
    "        labels.append(1 if split[0] == \"spam\" else 0)\n",
    "        texts.append(split[1])\n",
    "df = pl.DataFrame({\"label\": labels, \"text\": texts})\n",
    "\n",
    "connection = Connection(\"localhost\")\n",
    "\n",
    "\n",
    "policy = Policy(safe_zone=Aggregation(min_agg_size=10), unsafe_handling=Log())\n",
    "rdf = connection.client.polars.send_df(df, policy=policy, sanitized_columns=[\"text\"])\n",
    "\n",
    "ratio = 0.25\n",
    "train_rdf, test_rdf = train_test_split(rdf, test_size=ratio, shuffle=True)\n",
    "\n",
    "tokenizer = Tokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokenizer.enable_truncation(max_length=32)\n",
    "tokenizer.enable_padding(length=32)\n",
    "\n",
    "train_rds = (\n",
    "    train_rdf.convert([\"text\"], tokenizer.to_str())\n",
    "    .collect()\n",
    "    .to_dataset([\"text_ids\", \"text_mask\"], \"label\")\n",
    ")\n",
    "test_rds = (\n",
    "    test_rdf.convert([\"text\"], tokenizer.to_str())\n",
    "    .collect()\n",
    "    .to_dataset([\"text_ids\", \"text_mask\"], \"label\")\n",
    ")\n",
    "\n",
    "\n",
    "train_rds._set_test_dataset(test_rds.train_dataset_ref)\n",
    "test_rds.set_train_dataset(train_dataset=train_rds.train_dataset_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "from bastionlab.torch.utils import MultipleOutputWrapper\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    torchscript=True,\n",
    ")\n",
    "model = MultipleOutputWrapper(model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<bastionlab.torch.learner.RemoteDataset object at 0x7fddc8777be0>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_datasets = connection.client.torch.list_remote_datasets()\n",
    "print(remote_datasets)\n",
    "\n",
    "remote_datasets[0].trace_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending DistilBERT: 100%|████████████████████| 268M/268M [00:05<00:00, 46.9MB/s] \n"
     ]
    }
   ],
   "source": [
    "from bastionlab.torch.optimizer_config import Adam\n",
    "\n",
    "remote_learner = connection.client.torch.RemoteLearner(\n",
    "    model,\n",
    "    remote_datasets[0],\n",
    "    max_batch_size=2,\n",
    "    loss=\"cross_entropy\",\n",
    "    optimizer=Adam(lr=5e-5),\n",
    "    model_name=\"DistilBERT\",\n",
    "    expand=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 - train:   0%|                    | 5/2090 [00:12<1:25:39,  2.46s/batch, cross_entropy=0.0000 (+/- 3729.0254)] "
     ]
    },
    {
     "ename": "GRPCException",
     "evalue": "Connection to the gRPC server failed: code=StatusCode.UNAVAILABLE message=Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/errors.py:70\u001b[0m, in \u001b[0;36mGRPCException.map_error\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mreturn\u001b[39;00m f()\n\u001b[1;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m _InactiveRpcError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/torch/client.py:198\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest\u001b[39m(\u001b[39mself\u001b[39m, config: TestConfig) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Reference:\n\u001b[1;32m    196\u001b[0m     \u001b[39m\"\"\"Tests a dataset on a model according to `config` on the BastionAI server.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[0;32m--> 198\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m        config: Testing configuration that specifies the model, dataset and hyperparameters.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mrefresh_session_if_needed()\n",
      "File \u001b[0;32m~/base/lib/python3.8/site-packages/grpc/_channel.py:946\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    944\u001b[0m state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    945\u001b[0m                               wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0m \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/base/lib/python3.8/site-packages/grpc/_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"Connection reset by peer\"\n\tdebug_error_string = \"{\"created\":\"@1672743111.470227510\",\"description\":\"Error received from peer ipv4:127.0.0.1:50056\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":966,\"grpc_message\":\"Connection reset by peer\",\"grpc_status\":14}\"\n>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mGRPCException\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/kbamponsem/Projects/bastionlab/docs/docs/tutorials/data_conversion.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kbamponsem/Projects/bastionlab/docs/docs/tutorials/data_conversion.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m remote_learner\u001b[39m.\u001b[39;49mfit(nb_epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, eps\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/torch/learner.py:467\u001b[0m, in \u001b[0;36mRemoteLearner.fit\u001b[0;34m(self, nb_epochs, eps, batch_size, max_grad_norm, lr, metric_eps, timeout, poll_delay, per_n_epochs_checkpoint, per_n_steps_checkpoint, resume)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39m\"\"\"Fits the uploaded model to the training dataset with given hyperparameters.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \n\u001b[1;32m    443\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39m    poll_delay: Delay in seconds between two polling requests for the loss.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m run \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mtrain(\n\u001b[1;32m    455\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_config(\n\u001b[1;32m    456\u001b[0m         nb_epochs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    465\u001b[0m     )\n\u001b[1;32m    466\u001b[0m )\n\u001b[0;32m--> 467\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll_metric(\n\u001b[1;32m    468\u001b[0m     run,\n\u001b[1;32m    469\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss,\n\u001b[1;32m    470\u001b[0m     train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    471\u001b[0m     timeout\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(timeout \u001b[39m/\u001b[39;49m poll_delay),\n\u001b[1;32m    472\u001b[0m     poll_delay\u001b[39m=\u001b[39;49mpoll_delay,\n\u001b[1;32m    473\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/torch/learner.py:392\u001b[0m, in \u001b[0;36mRemoteLearner._poll_metric\u001b[0;34m(self, run, name, train, timeout, poll_delay)\u001b[0m\n\u001b[1;32m    390\u001b[0m prev_batch \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mbatch\n\u001b[1;32m    391\u001b[0m prev_epoch \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mepoch\n\u001b[0;32m--> 392\u001b[0m metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mget_metric(run)\n\u001b[1;32m    394\u001b[0m \u001b[39m# Handle end of training\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m metric\u001b[39m.\u001b[39mbatch \u001b[39m==\u001b[39m prev_batch \u001b[39mand\u001b[39;00m metric\u001b[39m.\u001b[39mepoch \u001b[39m==\u001b[39m prev_epoch:\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/torch/client.py:198\u001b[0m, in \u001b[0;36mget_metric\u001b[0;34m(self, run)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest\u001b[39m(\u001b[39mself\u001b[39m, config: TestConfig) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Reference:\n\u001b[1;32m    196\u001b[0m     \u001b[39m\"\"\"Tests a dataset on a model according to `config` on the BastionAI server.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[0;32m--> 198\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m        config: Testing configuration that specifies the model, dataset and hyperparameters.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mrefresh_session_if_needed()\n\u001b[1;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m GRPCException\u001b[39m.\u001b[39mmap_error(\u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstub\u001b[39m.\u001b[39mTest(config))\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/errors.py:72\u001b[0m, in \u001b[0;36mGRPCException.map_error\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m f()\n\u001b[1;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m _InactiveRpcError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mraise\u001b[39;00m GRPCException(e)\n\u001b[1;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m _MultiThreadedRendezvous \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     74\u001b[0m     \u001b[39mraise\u001b[39;00m GRPCException(e)\n",
      "\u001b[0;31mGRPCException\u001b[0m: Connection to the gRPC server failed: code=StatusCode.UNAVAILABLE message=Connection reset by peer"
     ]
    }
   ],
   "source": [
    "remote_learner.fit(nb_epochs=2, eps=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfb725626286d8c8fc5334ffe77697f720dc23e64d3046271825a5556b528e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
