{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"colab_button\">\n",
    "  <h1>Text Data Preprocessing</h1>\n",
    "  <a target=\"_blank\" href=\"https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.7/docs/docs/tutorials/string_preprocessing.ipynb\"> \n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "</div>\n",
    "\n",
    "----------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning is an essential preparation step for both data analysis and machine learning tasks - and this include dealing with textual data! But this type of data comes with its own unique preprocessing challenges: such as handling different casing or misspelt words. \n",
    "\n",
    "It is the data scientist's job to clean it sufficiently to ensure it will be grouped together correctly and give accurate query results and predictions. For this, you need the right tools...\n",
    "\n",
    "In this tutorial, we'll see BastionLab's text pre-processing tools and how to use them, by becoming a data scientist performing text preprocessing for an Natural Language Processing task. We will go through some essential string manipulation functions such as splitting strings, removing stop words and changing case, while manipulating remote dataframes with safety guarantees.\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "___________________________________________\n",
    "\n",
    "### Installation and dataset\n",
    "\n",
    "In order to run this notebook, we need to:\n",
    "- Have [Python3.7](https://www.python.org/downloads/) (or greater) and [Python Pip](https://pypi.org/project/pip/) installed\n",
    "- Install [BastionLab](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/)\n",
    "- Download [the dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip) we will be using in this tutorial.\n",
    "\n",
    "We'll do so by running the code block below. \n",
    "\n",
    ">If you are running this notebook on your machine instead of [Google Colab](https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.7/docs/docs/tutorials/string_preprocessing.ipynb), you can see our [Installation page](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/) to find the installation method that best suits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bastionlab\n",
    "!pip install bastionlab_server\n",
    "\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
    "!unzip smsspamcollection.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [SMS Spam Dataset](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) contains close to 5000 messages tagged as legitimate or spam messages.  It contains 425 spam SMS messages and 3,357 \"ham\" (genuine) messages. \n",
    "\n",
    "You can read more about the dataset [here](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch and connect to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch bastionlab_server test package\n",
    "import bastionlab_server\n",
    "\n",
    "srv = bastionlab_server.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Note that the bastionlab_server package we install here was created for testing purposes. You can also install BastionLab server using our Docker image or from source (especially for non-test purposes). Check out our [Installation Tutorial](../getting-started/installation.md) for more details.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the server\n",
    "from bastionlab import Connection\n",
    "\n",
    "connection = Connection(\"localhost\")\n",
    "client = connection.client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a Polars dataframe from the CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most case, you can feed your csv file to Polars `read_csv()` function to create a dataframe and it works - except if the dataset you're using doesn't have a header! Then it would use the first line of the dataset as column names and the resulting dataframe would be wrong. \n",
    "\n",
    "We can check if a dataset has a header by inspecting the top two lines of the dataset. We'll use Linux's `head` command with the `-n 2` option and... we see that the CSV file doesn't have a header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "ham\tOk lar... Joking wif u oni...\n"
     ]
    }
   ],
   "source": [
    "# inspect first two rows of dataset\n",
    "!head -n 2 SMSSpamCollection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to let `read_csv` know that the CSV file has no header. We can do this using the `has_header=False` option, then supply our desired column names with the `new_columns` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (1, 2)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "label\n",
       "</th>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Go until juron...\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (1, 2)\n",
       "┌───────┬─────────────────────────────────────┐\n",
       "│ label ┆ text                                │\n",
       "│ ---   ┆ ---                                 │\n",
       "│ str   ┆ str                                 │\n",
       "╞═══════╪═════════════════════════════════════╡\n",
       "│ ham   ┆ Go until jurong point, crazy.. A... │\n",
       "└───────┴─────────────────────────────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# read CSV file using Polars and name columns `text` and `label`\n",
    "df = pl.read_csv(\n",
    "    \"SMSSpamCollection\", has_header=False, sep=\"\\t\", new_columns=[\"label\", \"text\"]\n",
    ")\n",
    "# display the first row of the dataset and column names\n",
    "df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our Polars DataFrame, it's time to upload it to the BastionLab server."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the dataframe to the server\n",
    "\n",
    "Before we upload the dataset to the server, we'll create a custom privacy policy which will allow us to run whatever query we want! To do this we will create a `Policy` with the `safe_zone` option set to `TrueRule()`, which means all queries will be considered safe. We would normally use a much stricter policy, but this policy is useful for the purposes of this demo as it allows us to print out sections of the raw data!\n",
    "\n",
    "> Read more about policies [here](https://github.com/mithril-security/bastionlab/blob/v0.3.7/docs/docs/tutorials/defining_policy_privacy.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bastionlab.polars.policy import Policy, TrueRule, Log\n",
    "\n",
    "# create our open policy\n",
    "policy = Policy(safe_zone=TrueRule(), unsafe_handling=Log(), savable=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created our custom policy, we will use the `send_df` function to upload our dataset to the BastionLab server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchableLazyFrame(identifier=1fb34c9b-d680-4301-b847-cf949b4d0bde)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload DataFrame to BastionLab server\n",
    "rdf = client.polars.send_df(df, policy=policy)\n",
    "\n",
    "rdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The server returns a `RemoteLazyFrame` which allows us to work with the dataset remotely. We will be working with this RemoteLazyFrame for the rest of this tutorial!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing our text data \n",
    "--------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Note: The following string methods are very much similar to the operations applied on strings in Python._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capitalizing the text\n",
    "We can use the `to_lowercase()` and `to_uppercase()` methods to set all the strings in our `RemoteDataFrame` to lowercase or uppercase. This can be really handy if you want to group data together by string without worrying about variations in casing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (5278, 2)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "label\n",
       "</th>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;go until juron...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;ok lar... joki...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;free entry in ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;u dun say so e...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;nah i don&#x27;t th...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;freemsg hey th...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;even my brothe...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;as per your re...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;winner!! as a ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;had your mobil...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;i&#x27;m gonna be h...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;six chances to...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;anything lor. ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;get me out of ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;ok lor... sony...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;ard 6 like dat...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;why don&#x27;t you ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;huh y lei...&quot;\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;reminder from ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;this is the 2n...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;will ü b going...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;pity, * was in...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;the guy did so...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;rofl. its true...\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (5278, 2)\n",
       "┌───────┬─────────────────────────────────────┐\n",
       "│ label ┆ text                                │\n",
       "│ ---   ┆ ---                                 │\n",
       "│ str   ┆ str                                 │\n",
       "╞═══════╪═════════════════════════════════════╡\n",
       "│ ham   ┆ go until jurong point, crazy.. a... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ ok lar... joking wif u oni...       │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ spam  ┆ free entry in 2 a wkly comp to w... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ u dun say so early hor... u c al... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ...   ┆ ...                                 │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ will ü b going to esplanade fr h... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ pity, * was in mood for that. so... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ the guy did some bitching but i ... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ rofl. its true to its name          │\n",
       "└───────┴─────────────────────────────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set rdf to all lowercase\n",
    "rdf = rdf.to_lowercase()\n",
    "\n",
    "# display results\n",
    "rdf.collect().fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (5278, 2)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "label\n",
       "</th>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;GO UNTIL JURON...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;OK LAR... JOKI...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;FREE ENTRY IN ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;U DUN SAY SO E...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;NAH I DON&#x27;T TH...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;FREEMSG HEY TH...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;EVEN MY BROTHE...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;AS PER YOUR RE...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;WINNER!! AS A ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;HAD YOUR MOBIL...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;I&#x27;M GONNA BE H...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;SIX CHANCES TO...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;ANYTHING LOR. ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;GET ME OUT OF ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;OK LOR... SONY...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;ARD 6 LIKE DAT...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;WHY DON&#x27;T YOU ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;HUH Y LEI...&quot;\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;REMINDER FROM ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;THIS IS THE 2N...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;WILL Ü B GOING...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;PITY, * WAS IN...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;THE GUY DID SO...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;ROFL. ITS TRUE...\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (5278, 2)\n",
       "┌───────┬─────────────────────────────────────┐\n",
       "│ label ┆ text                                │\n",
       "│ ---   ┆ ---                                 │\n",
       "│ str   ┆ str                                 │\n",
       "╞═══════╪═════════════════════════════════════╡\n",
       "│ HAM   ┆ GO UNTIL JURONG POINT, CRAZY.. A... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ HAM   ┆ OK LAR... JOKING WIF U ONI...       │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ SPAM  ┆ FREE ENTRY IN 2 A WKLY COMP TO W... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ HAM   ┆ U DUN SAY SO EARLY HOR... U C AL... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ...   ┆ ...                                 │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ HAM   ┆ WILL Ü B GOING TO ESPLANADE FR H... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ HAM   ┆ PITY, * WAS IN MOOD FOR THAT. SO... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ HAM   ┆ THE GUY DID SOME BITCHING BUT I ... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ HAM   ┆ ROFL. ITS TRUE TO ITS NAME          │\n",
       "└───────┴─────────────────────────────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the dataset with all uppercase strings\n",
    "rdf.to_uppercase().collect().fetch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing punctuations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to remove all punctuations from our strings.\n",
    "\n",
    "To do this, we will use the `replace_all()` method to replace anything that doesn't match our regular expression pattern with `\"\"`, effectively deleting it. Our regular expression matches on any combination of lowercase letters (a-z) - since the dataset is set to all lowercase -, numbers (0-9) and whitespaces (\\s). Anything else is considered to be punctuation and is removed.\n",
    "\n",
    "> You can find out more about regular expression [here](https://learn.microsoft.com/en-us/previous-versions/visualstudio/visual-studio-2010/ae5bf541(v=vs.100)?redirectedfrom=MSDN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (5278, 2)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "label\n",
       "</th>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;go until juron...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;ok lar joking ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;free entry in ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;u dun say so e...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;nah i dont thi...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;freemsg hey th...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;even my brothe...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;as per your re...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;winner as a va...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;had your mobil...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;im gonna be ho...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;six chances to...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;anything lor j...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;get me out of ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;ok lor sony er...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;ard 6 like dat...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;why dont you w...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;huh y lei&quot;\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;reminder from ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;this is the 2n...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;will  b going ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;pity  was in m...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;the guy did so...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;rofl its true ...\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (5278, 2)\n",
       "┌───────┬─────────────────────────────────────┐\n",
       "│ label ┆ text                                │\n",
       "│ ---   ┆ ---                                 │\n",
       "│ str   ┆ str                                 │\n",
       "╞═══════╪═════════════════════════════════════╡\n",
       "│ ham   ┆ go until jurong point crazy avai... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ ok lar joking wif u oni             │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ spam  ┆ free entry in 2 a wkly comp to w... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ u dun say so early hor u c alrea... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ...   ┆ ...                                 │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ will  b going to esplanade fr ho... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ pity  was in mood for that soany... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ the guy did some bitching but i ... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ rofl its true to its name           │\n",
       "└───────┴─────────────────────────────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf = rdf.replace_all(pattern=\"[^a-z0-9\\\\\\s]+\", to=\"\").collect()\n",
    "rdf.fetch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching words in a fuzzy manner"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, patterns and comparisons aren't so easy to make. That's when fuzzy string matching comes into play. It is the process of finding strings that approximately match a pattern by using values ranging between 1 and 0. Where `booleans` are either true or false, fuzzy logic reasons that a value can be somewhat true, somewhat false, completely true, etc. \n",
    "\n",
    "To explore this method, you can use our `fuzzy_match()` function. It filters out text including anything similar to the `pattern` provided in selected columns (`cols`).\n",
    "\n",
    "The cells containing words that are near-matches to the pattern are returned in full. Cells that do not contain fuzzy matches of the pattern will be shown as `null`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (5278, 2)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "label\n",
       "</th>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;go until juron...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;free entry in ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;nah i dont thi...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;freemsg hey th...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;as per your re...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;had your mobil...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;im gonna be ho...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;six chances to...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;reminder from ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;pity  was in m...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;the guy did so...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;rofl its true ...\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (5278, 2)\n",
       "┌───────┬─────────────────────────────────────┐\n",
       "│ label ┆ text                                │\n",
       "│ ---   ┆ ---                                 │\n",
       "│ str   ┆ str                                 │\n",
       "╞═══════╪═════════════════════════════════════╡\n",
       "│ ham   ┆ go until jurong point crazy avai... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ null                                │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ spam  ┆ free entry in 2 a wkly comp to w... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ null                                │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ...   ┆ ...                                 │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ null                                │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ pity  was in mood for that soany... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ the guy did some bitching but i ... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ rofl its true to its name           │\n",
       "└───────┴─────────────────────────────────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.fuzzy_match(pattern=\"free\", cols=[\"text\"]).collect().fetch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the frequency of words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can search for all occurrences matching a specific pattern with `findall()`. \n",
    "\n",
    "Here we'll search for `free` and we use `(i)`regex flag to specify that we want to match on this word, regardless of casing.\n",
    "\n",
    "We store this in a DataFrame where the `text` column now contains lists with each found match of `free`. A sentence that does not contain `free` becomes an empty list `[]`, and an entry containing `free` twice becomes `[\"free\", \"free\"]`.\n",
    "\n",
    "We can then get the total number of matches by using the `lengths()` and `sum()` methods. It will convert our lists to a number representing the length of the list and then sum up all these lengths to give us our total frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (1, 1)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "u32\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "327\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌──────┐\n",
       "│ text │\n",
       "│ ---  │\n",
       "│ u32  │\n",
       "╞══════╡\n",
       "│ 327  │\n",
       "└──────┘"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save results of findall in DataFrame\n",
    "df = rdf.findall(pattern=\"(?i)free\").collect().fetch()\n",
    "\n",
    "# Get number of matches for each sentence by using the arr.lengths(), then use sum to get the total matches\n",
    "df.select(pl.col(\"text\").arr.lengths()).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the results above that there are `327` occurrences of the word `free` in our `RemoteDataFrame`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of rows containing a word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method of finding occurences is `contains()`. It gets the total number of rows that contain a word at least once.\n",
    "\n",
    "`contains()` will fill our `text` column with true (`1`) where a match for our word is found and false (`0`) where no matches are found. We can use `sum` directly on this data to get the total number of rows which contained matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (1, 2)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "label\n",
       "</th>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "u32\n",
       "</td>\n",
       "<td>\n",
       "u32\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "0\n",
       "</td>\n",
       "<td>\n",
       "249\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (1, 2)\n",
       "┌───────┬──────┐\n",
       "│ label ┆ text │\n",
       "│ ---   ┆ ---  │\n",
       "│ u32   ┆ u32  │\n",
       "╞═══════╪══════╡\n",
       "│ 0     ┆ 249  │\n",
       "└───────┴──────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.contains(\"(?i)free\").sum().collect().fetch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing our sentences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can tokenize our sentences into words, so they can easily be transformed for AI training tasks (here, NLP with the spam dataset).\n",
    "\n",
    "We will use the `split()` method to do this, which will transform our messages into lists of words. Whitespace characters are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (5278, 2)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "label\n",
       "</th>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "list[str]\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;go&quot;, &quot;until&quot;, ... &quot;wat&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;ok&quot;, &quot;lar&quot;, ... &quot;oni&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;free&quot;, &quot;entry&quot;, ... &quot;08452810075over18s&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;u&quot;, &quot;dun&quot;, ... &quot;say&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;nah&quot;, &quot;i&quot;, ... &quot;though&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;freemsg&quot;, &quot;hey&quot;, ... &quot;rcv&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;even&quot;, &quot;my&quot;, ... &quot;patent&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;as&quot;, &quot;per&quot;, ... &quot;callertune&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;winner&quot;, &quot;as&quot;, ... &quot;only&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;had&quot;, &quot;your&quot;, ... &quot;08002986030&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;im&quot;, &quot;gonna&quot;, ... &quot;today&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;six&quot;, &quot;chances&quot;, ... &quot;info&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;anything&quot;, &quot;lor&quot;, ... &quot;lor&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;get&quot;, &quot;me&quot;, ... &quot;boring&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;ok&quot;, &quot;lor&quot;, ... &quot;considering&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;ard&quot;, &quot;6&quot;, ... &quot;lor&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;why&quot;, &quot;dont&quot;, ... &quot;&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;huh&quot;, &quot;y&quot;, &quot;lei&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;reminder&quot;, &quot;from&quot;, ... &quot;postcode&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;this&quot;, &quot;is&quot;, ... &quot;btnationalrate&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;will&quot;, &quot;&quot;, ... &quot;home&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;pity&quot;, &quot;&quot;, ... &quot;suggestions&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;the&quot;, &quot;guy&quot;, ... &quot;free&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;rofl&quot;, &quot;its&quot;, ... &quot;name&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (5278, 2)\n",
       "┌───────┬─────────────────────────────────────┐\n",
       "│ label ┆ text                                │\n",
       "│ ---   ┆ ---                                 │\n",
       "│ str   ┆ list[str]                           │\n",
       "╞═══════╪═════════════════════════════════════╡\n",
       "│ ham   ┆ [\"go\", \"until\", ... \"wat\"]          │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ [\"ok\", \"lar\", ... \"oni\"]            │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ spam  ┆ [\"free\", \"entry\", ... \"084528100... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ [\"u\", \"dun\", ... \"say\"]             │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ...   ┆ ...                                 │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ [\"will\", \"\", ... \"home\"]            │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ [\"pity\", \"\", ... \"suggestions\"]     │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ [\"the\", \"guy\", ... \"free\"]          │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ [\"rofl\", \"its\", ... \"name\"]         │\n",
       "└───────┴─────────────────────────────────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf = rdf.split(sep=\" \", cols=[\"text\"]).collect()\n",
    "rdf.fetch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're good to go! Let's now close the connection and shutdown the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()\n",
    "bastionlab_server.stop(srv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
