{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"colab_button\">\n",
    "  <h1>Text Data Preprocessing</h1>\n",
    "  <a target=\"_blank\" href=\"https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.7/docs/docs/tutorials/string_preprocessing.ipynb\"> \n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "</div>\n",
    "\n",
    "----------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will be processing the [SMS Spam Collection](https://archive.ics.uci.edu/ml/machine-learning-databases/00228/) dataset.\n",
    "\n",
    "We will see how to split strings, remove stop words, match cases, and a few other string operations that could be done on our `RemoteDataFrame`. If you want to know more about `RemoteDataFrame`s, kindly check out out [Remote Data Science](https://github.com/mithril-security/bastionlab/blob/v0.3.7/docs/docs/concepts-guides/remote_data_science.md) concept guide.\n",
    "\n",
    "Also, we will be preprocessing our text as if it would be used in an NLP task.\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "___________________________________________\n",
    "\n",
    "### Installation and dataset\n",
    "\n",
    "In order to run this notebook, we need to:\n",
    "- Have [Python3.7](https://www.python.org/downloads/) (or greater) and [Python Pip](https://pypi.org/project/pip/) installed\n",
    "- Install [BastionLab](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/)\n",
    "- Download [the dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip) we will be using in this tutorial.\n",
    "- Install [Polars](https://pypi.org/project/polars/)\n",
    "\n",
    "We'll do so by running the code block below. \n",
    "\n",
    ">If you are running this notebook on your machine instead of [Google Colab](https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.7/docs/docs/tutorials/saving_dataframes.ipynb), you can see our [Installation page](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/) to find the installation method that best suits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bastionlab\n",
    "!pip install bastionlab_server\n",
    "!pip install polars\n",
    "\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
    "!unzip smsspamcollection.zip\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "The SMS Spam Dataset contains approximatively 5000 messages tagged as legitimate or spam messages. \n",
    "\n",
    "A collection of 425 SMS spam messages was manually extracted from the Grumbletext Web site. This is a UK forum in which cell phone users make public claims about SMS spam messages, most of them without reporting the very spam message received. \n",
    "\n",
    "A subset of 3,375 SMS randomly chosen ham (good) messages of the NUS SMS Corpus (NSC), which is a dataset of about 10,000 legitimate messages collected for research at the Department of Computer Science at the National University of Singapore. \n",
    "\n",
    "You can read more about the dataset [here](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection).\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch and connect to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch bastionlab_server test package\n",
    "import bastionlab_server\n",
    "\n",
    "srv = bastionlab_server.start()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Note that the bastionlab_server package we install here was created for testing purposes. You can also install BastionLab server using our Docker image or from source (especially for non-test purposes). Check out our [Installation Tutorial](../getting-started/installation.md) for more details.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the server\n",
    "from bastionlab import Connection\n",
    "\n",
    "connection = Connection(\"localhost\")\n",
    "client = connection.client\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "ham\tOk lar... Joking wif u oni...\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 SMSSpamCollection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `head` command on the SMSSpamCollection file, we observe that the CSV file doesn't have a header and so, we would have to give it one when we load the file using Polars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Read CSV file using Polars and rename columns with `text`, `label`\n",
    "df = pl.read_csv(\n",
    "    \"SMSSpamCollection\", has_header=False, sep=\"\\t\", new_columns=[\"label\", \"text\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the CSV file by setting the `has_header` flag to `False` and passing our headers `label` and `text` to the `read_csv` method."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the dataframe to the server\n",
    "\n",
    "Before we upload the dataset to the server, we'll create a custom privacy policy which essentially passes all queries. \n",
    "\n",
    "> Note that we only use the `TrueRule` for testing and in a production environment, you might want to use the `Aggregate` policy. Read more about policies [here](https://github.com/mithril-security/bastionlab/blob/v0.3.7/docs/docs/tutorials/defining_policy_privacy.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchableLazyFrame(identifier=a7b39af4-2171-470f-9ce1-5e459eae40c2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bastionlab.polars.policy import Policy, TrueRule, Log\n",
    "\n",
    "policy = Policy(safe_zone=TrueRule(), unsafe_handling=Log(), savable=False)\n",
    "\n",
    "rdf = client.polars.send_df(df, policy=policy)\n",
    "\n",
    "rdf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The server returns a `RemoteLazyFrame` which we will be working with throughout the rest of this tutorial!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing our text collection \n",
    "--------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: An important point to note is that all these string methods are very much similar to the operations applied on strings in Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capitalizing our texts\n",
    "We will use the `to_lowercase` method to ensure that all the strings in our `RemoteDataFrame` are in lowercase.\n",
    "\n",
    "_You could also call `to_uppercase` on the `RemoteDataFrame` to convert all the strings to uppercase._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (4774, 2)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "label\n",
       "</th>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;go until juron...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;ok lar... joki...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;free entry in ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;u dun say so e...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;nah i don&#x27;t th...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;freemsg hey th...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;even my brothe...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;as per your re...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;winner!! as a ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;had your mobil...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;i&#x27;m gonna be h...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;six chances to...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;hai dear frien...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;5p 4 alfie moo...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;as in differen...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;win a £200 sho...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;gud ni8 dear.....\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;i want to sent...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;this is the 2n...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;well, i&#x27;m glad...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;guy, no flash ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;do you want a ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;mark works tom...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;keep ur proble...\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (4774, 2)\n",
       "┌───────┬─────────────────────────────────────┐\n",
       "│ label ┆ text                                │\n",
       "│ ---   ┆ ---                                 │\n",
       "│ str   ┆ str                                 │\n",
       "╞═══════╪═════════════════════════════════════╡\n",
       "│ ham   ┆ go until jurong point, crazy.. a... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ ok lar... joking wif u oni...       │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ spam  ┆ free entry in 2 a wkly comp to w... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ u dun say so early hor... u c al... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ...   ┆ ...                                 │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ guy, no flash me now. if you go ... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ spam  ┆ do you want a new nokia 3510i co... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ mark works tomorrow. he gets out... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ keep ur problems in ur heart, b'... │\n",
       "└───────┴─────────────────────────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf = rdf.to_lowercase()\n",
    "rdf.collect().fetch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (4774, 2)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "label\n",
       "</th>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;GO UNTIL JURON...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;OK LAR... JOKI...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;FREE ENTRY IN ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;U DUN SAY SO E...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;NAH I DON&#x27;T TH...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;FREEMSG HEY TH...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;EVEN MY BROTHE...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;AS PER YOUR RE...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;WINNER!! AS A ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;HAD YOUR MOBIL...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;I&#x27;M GONNA BE H...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;SIX CHANCES TO...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;HAI DEAR FRIEN...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;5P 4 ALFIE MOO...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;AS IN DIFFEREN...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;WIN A £200 SHO...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;GUD NI8 DEAR.....\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;I WANT TO SENT...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;THIS IS THE 2N...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;WELL, I&#x27;M GLAD...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;GUY, NO FLASH ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;SPAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;DO YOU WANT A ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;MARK WORKS TOM...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;HAM&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;KEEP UR PROBLE...\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (4774, 2)\n",
       "┌───────┬─────────────────────────────────────┐\n",
       "│ label ┆ text                                │\n",
       "│ ---   ┆ ---                                 │\n",
       "│ str   ┆ str                                 │\n",
       "╞═══════╪═════════════════════════════════════╡\n",
       "│ HAM   ┆ GO UNTIL JURONG POINT, CRAZY.. A... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ HAM   ┆ OK LAR... JOKING WIF U ONI...       │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ SPAM  ┆ FREE ENTRY IN 2 A WKLY COMP TO W... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ HAM   ┆ U DUN SAY SO EARLY HOR... U C AL... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ...   ┆ ...                                 │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ HAM   ┆ GUY, NO FLASH ME NOW. IF YOU GO ... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ SPAM  ┆ DO YOU WANT A NEW NOKIA 3510I CO... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ HAM   ┆ MARK WORKS TOMORROW. HE GETS OUT... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ HAM   ┆ KEEP UR PROBLEMS IN UR HEART, B'... │\n",
       "└───────┴─────────────────────────────────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.to_uppercase().collect().fetch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing punctuations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we would want to remove all punctuations from our strings and have only words with which to continue.\n",
    "\n",
    "We will use this regular expression (`[^a-z0-9\\\\\\s]+`) to remove all punctuations.\n",
    "\n",
    "In order to remove all occurrences and not the first occurrence, we will use the method `replace_all` and not `replace`.\n",
    "\n",
    "> Kindly note that all methods are case-sensitive and the Regex flag `(?i)` or the right string to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (4774, 2)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "label\n",
       "</th>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;go until juron...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;ok lar joking ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;free entry in ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;u dun say so e...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;nah i dont thi...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;freemsg hey th...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;even my brothe...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;as per your re...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;winner as a va...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;had your mobil...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;im gonna be ho...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;six chances to...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;hai dear frien...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;5p 4 alfie moo...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;as in differen...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;win a 200 shop...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;gud ni8 dearsl...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;i want to sent...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;this is the 2n...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;well im glad y...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;guy no flash m...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;do you want a ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;mark works tom...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;keep ur proble...\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (4774, 2)\n",
       "┌───────┬─────────────────────────────────────┐\n",
       "│ label ┆ text                                │\n",
       "│ ---   ┆ ---                                 │\n",
       "│ str   ┆ str                                 │\n",
       "╞═══════╪═════════════════════════════════════╡\n",
       "│ ham   ┆ go until jurong point crazy avai... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ ok lar joking wif u oni             │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ spam  ┆ free entry in 2 a wkly comp to w... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ u dun say so early hor u c alrea... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ...   ┆ ...                                 │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ guy no flash me now if you go ca... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ spam  ┆ do you want a new nokia 3510i co... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ mark works tomorrow he gets out ... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ keep ur problems in ur heart bco... │\n",
       "└───────┴─────────────────────────────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf = rdf.replace_all(pattern=\"[^a-z0-9\\\\\\s]+\", to=\"\").collect()\n",
    "rdf.fetch()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching words in a fuzzy manner"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using our dataset for an machine learning tasks, let's try to filter out a few words which are more synanymous with spams to see how we can apply the fuzzy matching method on our `RemoteDataFrame`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (4774, 2)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "label\n",
       "</th>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;go until juron...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;free entry in ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;nah i dont thi...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;freemsg hey th...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;as per your re...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;had your mobil...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;im gonna be ho...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;six chances to...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;hai dear frien...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;5p 4 alfie moo...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;as in differen...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;well im glad y...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;do you want a ...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;keep ur proble...\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (4774, 2)\n",
       "┌───────┬─────────────────────────────────────┐\n",
       "│ label ┆ text                                │\n",
       "│ ---   ┆ ---                                 │\n",
       "│ str   ┆ str                                 │\n",
       "╞═══════╪═════════════════════════════════════╡\n",
       "│ ham   ┆ go until jurong point crazy avai... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ null                                │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ spam  ┆ free entry in 2 a wkly comp to w... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ null                                │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ...   ┆ ...                                 │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ null                                │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ spam  ┆ do you want a new nokia 3510i co... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ null                                │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ keep ur problems in ur heart bco... │\n",
       "└───────┴─────────────────────────────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.fuzzy_match(pattern=\"free\", cols=[\"text\"]).collect().fetch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (4774, 2)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "label\n",
       "</th>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;go until juron...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;freemsg hey th...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;as per your re...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;im gonna be ho...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;keep ur proble...\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (4774, 2)\n",
       "┌───────┬─────────────────────────────────────┐\n",
       "│ label ┆ text                                │\n",
       "│ ---   ┆ ---                                 │\n",
       "│ str   ┆ str                                 │\n",
       "╞═══════╪═════════════════════════════════════╡\n",
       "│ ham   ┆ go until jurong point crazy avai... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ null                                │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ spam  ┆ null                                │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ null                                │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ...   ┆ ...                                 │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ null                                │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ spam  ┆ null                                │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ null                                │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ keep ur problems in ur heart bco... │\n",
       "└───────┴─────────────────────────────────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.fuzzy_match(pattern=\"urgent\", cols=[\"text\"]).collect().fetch()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some fields have `null`. This is because there weren't matches found by the fuzzy matcher."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the frequency of words with findall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `findall`, we could be very specific with our search and return the found match in a list.\n",
    "\n",
    "Let's use find all to find the frequency of the word `free` in our `RemoteDataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (1, 1)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "u32\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "327\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌──────┐\n",
       "│ text │\n",
       "│ ---  │\n",
       "│ u32  │\n",
       "╞══════╡\n",
       "│ 327  │\n",
       "└──────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = rdf.findall(pattern=\"(?i)free\").collect().fetch()\n",
    "\n",
    "df.select(pl.col(\"text\").arr.lengths().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the results above that there are `327` instances of the word `free` in our `RemoteDataFrame`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word frequency but with booleans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contains acts like findall but returns a boolean if a match was found or not.\n",
    "\n",
    "We could use the method `contains` to also perform the word frequency operation we just did above.\n",
    "\n",
    "Let's look at how we could do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (1, 1)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "literal\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "234\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌─────────┐\n",
       "│ literal │\n",
       "│ ---     │\n",
       "│ i64     │\n",
       "╞═════════╡\n",
       "│ 234     │\n",
       "└─────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = rdf.contains(\"(?i)free\").collect().fetch()\n",
    "\n",
    "df.select(\n",
    "    pl.when(pl.col(\"text\") == True).then(1).otherwise(0).sum(),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the results of the `contains` and that of `findall` are slightly different because for contains we only return a True when we find the first match."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing our sentences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final step would be to tokenize our sentences into words so they could be easily transformed for our NLP task.\n",
    "\n",
    "We will utilize the `split` method for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (4774, 2)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "label\n",
       "</th>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "list[str]\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;go&quot;, &quot;until&quot;, ... &quot;wat&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;ok&quot;, &quot;lar&quot;, ... &quot;oni&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;free&quot;, &quot;entry&quot;, ... &quot;08452810075over18s&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;u&quot;, &quot;dun&quot;, ... &quot;say&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;nah&quot;, &quot;i&quot;, ... &quot;though&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;freemsg&quot;, &quot;hey&quot;, ... &quot;rcv&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;even&quot;, &quot;my&quot;, ... &quot;patent&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;as&quot;, &quot;per&quot;, ... &quot;callertune&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;winner&quot;, &quot;as&quot;, ... &quot;only&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;had&quot;, &quot;your&quot;, ... &quot;08002986030&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;im&quot;, &quot;gonna&quot;, ... &quot;today&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;six&quot;, &quot;chances&quot;, ... &quot;info&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;hai&quot;, &quot;dear&quot;, ... &quot;ranju&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;5p&quot;, &quot;4&quot;, ... &quot;charity&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;as&quot;, &quot;in&quot;, ... &quot;styles&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;win&quot;, &quot;a&quot;, ... &quot;150perweeksub&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;gud&quot;, &quot;ni8&quot;, ... &quot;dreamsmuah&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;i&quot;, &quot;want&quot;, ... &quot;hurts&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;this&quot;, &quot;is&quot;, ... &quot;09066361921&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;well&quot;, &quot;im&quot;, ... &quot;lol&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;guy&quot;, &quot;no&quot;, ... &quot;oh&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;spam&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;do&quot;, &quot;you&quot;, ... &quot;08000930705&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;mark&quot;, &quot;works&quot;, ... &quot;afterwards&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;ham&quot;\n",
       "</td>\n",
       "<td>\n",
       "[&quot;keep&quot;, &quot;ur&quot;, ... &quot;name&quot;]\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (4774, 2)\n",
       "┌───────┬─────────────────────────────────────┐\n",
       "│ label ┆ text                                │\n",
       "│ ---   ┆ ---                                 │\n",
       "│ str   ┆ list[str]                           │\n",
       "╞═══════╪═════════════════════════════════════╡\n",
       "│ ham   ┆ [\"go\", \"until\", ... \"wat\"]          │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ [\"ok\", \"lar\", ... \"oni\"]            │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ spam  ┆ [\"free\", \"entry\", ... \"084528100... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ [\"u\", \"dun\", ... \"say\"]             │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ...   ┆ ...                                 │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ [\"guy\", \"no\", ... \"oh\"]             │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ spam  ┆ [\"do\", \"you\", ... \"08000930705\"]    │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ [\"mark\", \"works\", ... \"afterward... │\n",
       "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ ham   ┆ [\"keep\", \"ur\", ... \"name\"]          │\n",
       "└───────┴─────────────────────────────────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf = rdf.split(sep=\" \", cols=[\"text\"]).collect()\n",
    "rdf.fetch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have our texts tokenized on `<space>`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now close the connection and shutdown the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bastionlab_server' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m connection\u001b[39m.\u001b[39mclose()\n\u001b[0;32m----> 2\u001b[0m bastionlab_server\u001b[39m.\u001b[39mstop(srv)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bastionlab_server' is not defined"
     ]
    }
   ],
   "source": [
    "# connection.close()\n",
    "# bastionlab_server.stop(srv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b02da7949da3af218e39ce2f31e32c0a1b93d864bdc2c2f7ec5cedc3569d5902"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
