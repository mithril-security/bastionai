{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Tour of BastionLab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why BastionLab?\n",
    "Data owners often need or wish that remote data scientists would access their datasets - like a hospital might want to valorize their data to external parties, startups, labs, or receive help from external experts, for instance. \n",
    "The problem is that the most popular solution is to give access to a Jupyter Python notebook installed on the data owner infrastructure. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/mithril-security/bastionlab/blob/master/docs/assets/current_solution.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is dangerous, because it exposes the dataset to serious data leakages. Jupyter was not made for this task and exfiltrating data can easily be done.\n",
    "That is why we have built BastionLab, a data science framework to perform remote and secure Exploratory Data Analysis. Data scientists can remotely run queries on data frames without seeing the original data or intermediary results - according to the strict privacy policies defined by the data owner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/mithril-security/bastionlab/blob/master/docs/assets/proposed_solution.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BastionLab features include:\n",
    "- Showing only aggregated results to maintain privacy with a minimal sample size to ensure the anonymization of each individual\n",
    "- When case rows have to be displayed, only a minimal amount of information is shown, and all data shared is recorded and tracked. \n",
    "\n",
    "Differential Privacy will be integrated transparently in the future.\n",
    "\n",
    "Technically, the framework uses polars (a Rust equivalent of pandas) lazy API to construct the queries locally. Once built, the queries are sent to the remote server of BastionLab and executed, if they pass the privacy policy rules defined by the data owner. BastionLab supports most data wrangling operations, like selects, groupbys, joins…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial’s Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following notebook tutorial, we will show you how to install BastionLab and use a few basic functionalities. We’ll use a mock example in which the data owner puts a Titanic passengers dataset at the disposal of the data scientist. \n",
    "\n",
    "“Titanic - Machine Learning from Disaster” dataset can be found on Kaggle and downloaded with a free user account https://www.kaggle.com/competitions/titanic/data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is divided into three parts:\n",
    "- Installation of BastionLab Client and Server\n",
    "- The Data Owner's Side\n",
    "- The Data Scientist's Side\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the end, the data scientist will be able to do Exploratory Data Analysis remotely, under the constraints defined by the data owner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical Requirements\n",
    "\n",
    "To start this tutorial, ensure the following are already installed in your system:\n",
    "- Python3.7 or greater (get the latest version of Python at https://www.python.org/downloads/ or with your operating system’s package manager)\n",
    "- [Python Pip](https://pypi.org/project/pip/) (PyPi), the package manager\n",
    "- [Docker](https://www.docker.com/) \n",
    "\n",
    "*Here's the [Docker official tutorial](https://docker-curriculum.com/) to set it up on your computer.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlQTyrwwOT6P"
   },
   "source": [
    "## Installing BastionLab Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afLaK6QON7-U"
   },
   "outputs": [],
   "source": [
    "!pip install bastionlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing BastionLab Server\n",
    "\n",
    "### Using the official docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker pull mithrilsecuritysas/bastionlab:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To install Bastion Client or Server locally, refer to our more detailed [Installation Tutorial](docs/).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the keys\n",
    "\n",
    "BastionLab only accept request from authenticated users. Authentication is done with asymmetric cryptography: the data owners provides a list of authorized public keys to the server upon start up and all users must provide their corresponding private key to the client when they connect to the server. The client then transparently creates a session for the user.\n",
    "\n",
    "BastionLab provides a utility module to manage the keys. We will use it to create the public and private keys for a single user.\n",
    "\n",
    "Firts create two directories to store the keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir pubkeys\n",
    "!mkdir privkeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create the public and private keys using the BastionLab library. This may be done in the interpreter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bastionlab import SigningKey\n",
    "\n",
    "# We create the Data Owner's private and public keys.\n",
    "data_owner_signing_key = SigningKey.from_pem_or_generate(\"privkeys/data_owner.key.pem\")\n",
    "data_owner_public_key = data_owner_signing_key.pubkey.save_pem(\"pubkeys/data_owner.pem\")\n",
    "\n",
    "\"\"\"\n",
    "    In order to authentify the data scientist(s), the data onwer would have to start \n",
    "    an instance of the BastionLab server with all the **allow** public keys. In the case of \n",
    "    this tutorial, the data owner's public key and the public key of the data scientist(s)\n",
    "\n",
    "    And for the purpose of this tutorial, the data scientist public and private keys are created right below.\n",
    "\"\"\"\n",
    "\n",
    "data_scientist_signing_key = SigningKey.from_pem_or_generate(\"privkeys/data_scientist.key.pem\")\n",
    "data_scientist_public_key = data_scientist_signing_key.pubkey.save_pem(\"pubkeys/data_scientist.pem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we start the instance of the BastionLab server by running the following docker command while binding the `pubkeys` directory created above to the server. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqLROxasOf-d"
   },
   "source": [
    "## Running BastionLab Server\n",
    "\n",
    "### Using the official Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LTtSRCMFOfm3"
   },
   "outputs": [],
   "source": [
    "!docker run -p 50056:50056 --mount type=bind,source=$(pwd)/pubkeys,target=/app/bin/keys -d mithrilsecuritysas/bastionlab:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JA-3PuGqFpAx"
   },
   "source": [
    "# Data Owner's Side\n",
    "In this part of the notebook, the data owner can setup the BastionLab server in his infrastructure and share a dataset with a privacy policy in place.\n",
    "It is divided into two steps: \n",
    "- Uploading the dataset to BastionLab \n",
    "- Choose a privacy policy regarding data exposure to the data scientist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xX0tE-3zGOhT"
   },
   "source": [
    "### Upload the data frame to the BastionLab Client\n",
    "Once downloaded, you can use polars to load it as a DataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7tby18jsFlHC"
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.read_csv(\"titanic_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcZV2enRGdLk"
   },
   "source": [
    "To upload the DataFrame to BastionLab, first open a connection to the server by providing its hostname. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCzcU937GeOT"
   },
   "outputs": [],
   "source": [
    "from bastionlab import Connection\n",
    "\n",
    "connection = Connection('localhost', 50056, signing_key=data_owner_signing_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xj4VzVyrGx4o"
   },
   "source": [
    "Using BastionLab client, you may now upload your data to the server in a secure and private fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXZ-z0r7GxT2"
   },
   "outputs": [],
   "source": [
    "connection.client.send_df(\n",
    "    df,\n",
    "    policy={\"aggregation\": \"accept\", \"rows_default_behavior\": \"approval\"},\n",
    "    k=20,\n",
    "    protected_columns=[\"Sex\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jw6DdQStHIyr"
   },
   "source": [
    "### Privacy Policy Options\n",
    "BastionLab offers many options to finetune your Privacy Policy.<br>\n",
    "\n",
    "You can choose three types of actions for each type of query: `accept`, `reject`, and `approval`.<br>\n",
    "\n",
    "In the previous example, the data owner accepts aggregation queries automatically but requires approval for all other types of queries.<br>\n",
    "\n",
    "Change the parameter `k` to set the minimum number of rows per group in aggregation. If a query does not have at least the given minimum number of rows per group, it is *not* considered an aggregation, and the request is denied. This prevents queries that would specifically isolate an individual, which would in turn ease their identification (a process known as deanonymization in data privacy).<br>\n",
    "\n",
    "You can also protect a list of sensitive columns with protected_columns which prevents users from displaying them except in aggregation contexts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qRygAL_HL1g"
   },
   "source": [
    "### Reference Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEZ2gQENHHvL"
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from bastionlab import Connection\n",
    "\n",
    "df = pl.read_csv(\"titanic_train.csv\")\n",
    "\n",
    "with Connection(\"localhost\", 50056, signing_key=data_owner_signing_key) as client:\n",
    "    client.send_df(\n",
    "        df,\n",
    "        policy={\"aggregation\": \"accept\", \"default\": \"approval\"},\n",
    "        k=20,\n",
    "        protected_columns=[\"Sex\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EsucHv3IZ8l"
   },
   "source": [
    "## Data Scientist’s Side\n",
    "In this part, we’ll show how the data scientist can access the Data Owner’s dataset, run queries, fetch the results, and display them.\n",
    "\n",
    "This tutorial is divided into five steps:\n",
    "- Access the data owner’s dataset\n",
    "- Run queries\n",
    "- Fetching the results\n",
    "- Data visualization functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JMB8Vo6IlA5"
   },
   "source": [
    "### Access the Data Owner’s Dataset \n",
    "\n",
    "You'll encounter two core objects to access the dataset’s DataFrame in BastionLab: the RemoteLazyFrame and the FetchableLazyFrame.\n",
    "\n",
    "First, you’ll need a RemoteLazyFrame, which is a reference to the DataFrame uploaded by the data owner, along with some metadata such as the names and types of the columns. \n",
    "\n",
    "This reference allows you to remotely run queries on the DataFrame without the need to download it and without the ability to see the initial data or intermediary results. \n",
    "\n",
    "As we do not know the unique identifier of the DataFrame uploaded by the data owner, we start by asking the server to list all available DataFrames.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zTutluzrIU25"
   },
   "outputs": [],
   "source": [
    "import bastionlab\n",
    "\n",
    "# Replace the api_key value with your own API key\n",
    "api_key = \"DATA_SCIENTIST_API_KEY\"\n",
    "connection = Connection(\"localhost\", 50056, signing_key=data_scientist_signing_key)\n",
    "\n",
    "client = connection.client\n",
    "\n",
    "all_rdfs = client.list_dfs()\n",
    "\n",
    "rdf = all_rdfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEUumlO7I_hs"
   },
   "source": [
    "The server returns a list of FetchableLazyFrames, a specific kind of RemoteLazyFrames, that we can inspect. In our case, we can just take the first one as the data owner has only uploaded one DataFrame so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LW4aLKlIJC6b"
   },
   "source": [
    "### Running Queries\n",
    "\n",
    "Now that you have a RemoteLazyFrame corresponding to the data owner’s DataFrame, it is time to run some queries on it.\n",
    "\n",
    "To define these queries, you can directly use all the methods provided by polars’ lazy API. Here, the adjective lazy means that no computation will be run unless explicitly needed. This allows the data scientist to build queries with a Pythonic approach from the RemoteLazyFrame, and when an operation needs to be executed on the data, the query is serialized and sent to the server. \n",
    "\n",
    "This is done with the **collect() method** to trigger the execution of all the recorded operations on the server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrGcCK5VIwg0"
   },
   "outputs": [],
   "source": [
    "rdf1 = rdf.head(5)\n",
    "rdf2 = rdf1.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rf6C_13wJH10"
   },
   "source": [
    "In this example, the first line returns a new RemoteLazyFrame that records the head operation - nothing happens on the server. In the second line, however, the call to collect()  sends a query to the server instructing it to do a head operation, and will run it right away.\n",
    "\n",
    "\n",
    "What is key to understanding, is that **every call to collect() will create a new DataFame on the server side that contains the result**.\n",
    "\n",
    "**On the client side, collect() returns a new FetchableLazyFrame that references the result on the server.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd5LudClJO0Z"
   },
   "source": [
    "### Fetching Results\n",
    "\n",
    "At some point in your process, you will need to download the results to use them locally or to display them. This can be achieved with the fetch method.\n",
    "\n",
    "The fetch method is defined on the FetchableLazyFrame class which extends the RemoteLazyFrame class. \n",
    "\n",
    "Recall that we’ve already seen the two ways of getting FetchableLazyFrames: by listing available DataFrames on the server, and by calling collect() on any RemoteLazyFrame. \n",
    "In practice, this means that fetch() may only be called on references to DataFrames already available on the server or after a call to collect(). As no computation has run before you call collect(), it wouldn’t actually make sense to fetch() the result because it does not yet exist! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_8EGgopJRUi"
   },
   "outputs": [],
   "source": [
    "rdf.head(5).collect().fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuhVGJNfJVT5"
   },
   "source": [
    "In addition, fetch() downloads the result DataFrame after performing some checks on how it was obtained and what the data owner authorizes you to do in their policy. These checks allow BastionLab to uphold a decent level of privacy without too big an impact on your workflow. If you need more guarantees, we plan to support differential privacy in the future as an optional feature.\n",
    "\n",
    "In our case, the data owner has set up a policy which allows downloading aggregated DataFrames right away but requires approval for all others. This means that, for example, we cannot directly print out rows from the original DataFrame because it wouldn’t count as an aggregation. Instead, the server requires the data owner’s approval first. This explains the message printed in the terminal when we try to fetch() the result of the head operation. \n",
    "\n",
    "Here, the data owner has accepted to disclose the data, which will allow us to download and to display it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s now try a more involved query: we compute the survival rates of the passengers on the Titanic based on their ticket class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_class_rates = (\n",
    "    rdf.select([pl.col(\"Pclass\"), pl.col(\"Survived\")])\n",
    "    .groupby(pl.col(\"Pclass\"))\n",
    "    .agg(pl.col(\"Survived\").mean())\n",
    "    .sort(\"Survived\", reverse=True)\n",
    "    .collect()\n",
    "    .fetch()\n",
    ")\n",
    "per_class_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUoApr5UJna1"
   },
   "source": [
    "Once again, we must use:\n",
    "- collect() to run the computation on the server\n",
    "- fetch() to retrieve the result locally \n",
    "\n",
    "In this case, no message appears because the query involves an aggregation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElGtVk90JvoC"
   },
   "source": [
    "### Data Visualization Functions\n",
    "\n",
    "The data scientist can also use plotting functions to visualize data while still upholding data privacy. One example feature is that the data is aggregated by default and although the size of bins is modifiable when calling the functions, BastionLab will check that this value enables sufficient data anonymity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71-OMO3IJ713"
   },
   "source": [
    "#### Barplot\n",
    "\n",
    "You can generate a barplot visualization of the data showing the number of survivors per age category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2-2g_2RJ9TC"
   },
   "outputs": [],
   "source": [
    "rdf.barplot(col_x=\"Age\", col_y=\"Survived\", bins=10, palette=\"bright\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22dhl54HKR6D"
   },
   "source": [
    "![](https://github.com/mithril-security/bastionlab/blob/master/docs/assets/barplot.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4M6JbJmXKNGR"
   },
   "source": [
    "You can generate a scatterplot visualization of this relationship.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65nIvNBSKNt3"
   },
   "outputs": [],
   "source": [
    "rdf.scatterplot(col_x=\"Age\", col_y=\"Survived\", bins=2, color=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgcxV5MPKUgK"
   },
   "source": [
    "![](https://github.com/mithril-security/bastionlab/blob/master/docs/assets/scatterplot.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvmoAL6BKXpa"
   },
   "source": [
    "#### Curveplot\n",
    "\n",
    "You can generate a curveplot to create a regression best-fit curve visualization of this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VplE4fOFKdyD"
   },
   "outputs": [],
   "source": [
    "rdf.curveplot(col_x=\"Age\", col_y=\"Survived\", bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3QvvaloKgcg"
   },
   "source": [
    "![](https://github.com/mithril-security/bastionlab/blob/master/docs/assets/curveplot.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrZA7dZnKido"
   },
   "source": [
    "For more information on these functions, check out our data visualization tutorial [here](../tutorials/visualization.ipynb)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b02da7949da3af218e39ce2f31e32c0a1b93d864bdc2c2f7ec5cedc3569d5902"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
