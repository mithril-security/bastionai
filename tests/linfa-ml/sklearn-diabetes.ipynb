{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/kbamponsem/base/lib/python3.8/site-packages (1.1.2)\n",
      "Requirement already satisfied: pandas in /home/kbamponsem/base/lib/python3.8/site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy in /home/kbamponsem/base/lib/python3.8/site-packages (1.23.1)\n",
      "Requirement already satisfied: matplotlib in /home/kbamponsem/base/lib/python3.8/site-packages (3.5.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/kbamponsem/base/lib/python3.8/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/kbamponsem/base/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/kbamponsem/base/lib/python3.8/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/kbamponsem/base/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/kbamponsem/base/lib/python3.8/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/kbamponsem/base/lib/python3.8/site-packages (from matplotlib) (4.37.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/kbamponsem/base/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/kbamponsem/base/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kbamponsem/base/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/kbamponsem/base/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/kbamponsem/base/lib/python3.8/site-packages (from matplotlib) (9.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/kbamponsem/base/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 59.       2.      32.1    101.     157.      93.2     38.       4.\n",
      "   4.8598  87.    ]\n"
     ]
    }
   ],
   "source": [
    "diabetes = datasets.load_diabetes(scaled=False)\n",
    "print(diabetes[\"data\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will split the data into the independent and independent variable\n",
    "X = diabetes.data\n",
    "Y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=99\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((309, 10), (309,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 67.       2.      22.5     98.     191.     119.2     61.       3.\n",
      "    3.989   86.    ]\n",
      " [ 53.       1.      28.      88.     233.     143.8     58.       4.\n",
      "    5.0499  91.    ]\n",
      " [ 41.       1.      23.1     86.     148.      78.      58.       3.\n",
      "    4.0943  60.    ]\n",
      " [ 65.       2.      33.5    102.     190.     126.2     35.       5.\n",
      "    4.9698 102.    ]\n",
      " [ 41.       1.      20.5     80.     124.      48.8     64.       2.\n",
      "    4.0254  75.    ]\n",
      " [ 48.       1.      32.7     93.     276.     198.6     43.       6.42\n",
      "    5.1475  91.    ]\n",
      " [ 61.       2.      32.7     97.     177.     118.4     29.       6.\n",
      "    4.9972  87.    ]\n",
      " [ 33.       1.      18.9     70.     162.      91.8     59.       3.\n",
      "    4.0254  58.    ]\n",
      " [ 48.       1.      22.8    101.     110.      41.6     56.       2.\n",
      "    4.1271  97.    ]\n",
      " [ 62.       2.      37.8    119.     113.      51.      31.       4.\n",
      "    5.0434  84.    ]\n",
      " [ 47.       2.      22.5     82.     131.      66.8     41.       3.\n",
      "    4.7536  89.    ]\n",
      " [ 29.       1.      35.      98.33   204.     142.6     50.       4.08\n",
      "    4.0431  91.    ]\n",
      " [ 28.       1.      22.1     82.     168.     100.6     54.       3.\n",
      "    4.2047  86.    ]\n",
      " [ 48.       1.      20.4     98.     209.     139.4     46.       5.\n",
      "    4.7707  78.    ]\n",
      " [ 60.       2.      27.5    106.     229.     143.8     51.       4.\n",
      "    5.1417  91.    ]\n",
      " [ 58.       2.      38.     103.     150.     107.2     22.       7.\n",
      "    4.6444  98.    ]\n",
      " [ 53.       2.      33.1    117.     183.     119.      48.       4.\n",
      "    4.382  106.    ]\n",
      " [ 71.       2.      26.5    105.     281.     173.6     55.       5.\n",
      "    5.5683  84.    ]\n",
      " [ 49.       1.      19.8     88.     188.     114.8     57.       3.\n",
      "    4.3944  93.    ]\n",
      " [ 42.       1.      24.9     91.     204.     141.8     38.       5.\n",
      "    4.7958  89.    ]\n",
      " [ 37.       2.      27.7     93.     180.     119.4     30.       6.\n",
      "    5.0304  88.    ]\n",
      " [ 51.       2.      26.2    101.     161.      99.6     48.       3.\n",
      "    4.2047  88.    ]\n",
      " [ 79.       2.      23.3     88.     186.     128.4     33.       6.\n",
      "    4.8122 102.    ]\n",
      " [ 42.       2.      24.     107.     150.      85.      44.       3.\n",
      "    4.654   96.    ]\n",
      " [ 66.       2.      26.2    114.     255.     185.      56.       4.55\n",
      "    4.2485  92.    ]\n",
      " [ 57.       1.      36.1    117.     181.     108.2     34.       5.\n",
      "    5.2679 100.    ]\n",
      " [ 60.       2.      24.9     99.67   162.     106.6     43.       3.77\n",
      "    4.1271  95.    ]\n",
      " [ 50.       1.      31.8     82.     136.      69.2     55.       2.\n",
      "    4.0775  85.    ]\n",
      " [ 43.       1.      34.3     84.     256.     172.6     33.       8.\n",
      "    5.5294 104.    ]\n",
      " [ 61.       1.      24.6    101.     209.     106.8     77.       3.\n",
      "    4.8363  88.    ]\n",
      " [ 59.       2.      24.7    114.     152.     104.8     29.       5.\n",
      "    4.5109  88.    ]\n",
      " [ 54.       1.      23.2    110.67   238.     162.8     48.       4.96\n",
      "    4.9127 108.    ]\n",
      " [ 68.       1.      27.5    107.     241.     149.6     64.       4.\n",
      "    4.92    90.    ]\n",
      " [ 39.       2.      26.3    115.     218.     158.2     32.       7.\n",
      "    4.9345 109.    ]\n",
      " [ 36.       2.      22.      90.     160.      99.6     50.       3.\n",
      "    3.9512  82.    ]\n",
      " [ 33.       1.      25.3     85.     155.      85.      51.       3.\n",
      "    4.5539  70.    ]\n",
      " [ 24.       1.      25.3     84.     198.     131.4     40.       5.\n",
      "    4.8903  89.    ]\n",
      " [ 67.       1.      26.7    105.     225.     135.4     69.       3.\n",
      "    4.6347  96.    ]\n",
      " [ 50.       1.      31.     123.     178.     105.      48.       4.\n",
      "    4.8283  88.    ]\n",
      " [ 66.       1.      28.     101.     195.     129.2     40.       5.\n",
      "    4.8598  94.    ]\n",
      " [ 55.       2.      23.5     93.     177.     126.8     41.       4.\n",
      "    3.8286  83.    ]\n",
      " [ 54.       2.      27.7    113.     200.     128.4     37.       5.\n",
      "    5.1533 113.    ]\n",
      " [ 60.       1.      22.2    104.67   221.     105.4     60.       3.68\n",
      "    5.6276  93.    ]\n",
      " [ 57.       2.      25.6     96.     200.     133.      52.       3.85\n",
      "    4.3175 105.    ]\n",
      " [ 52.       1.      23.     107.     179.     123.7     42.5      4.21\n",
      "    4.1589  93.    ]\n",
      " [ 74.       1.      29.8    101.     171.     104.8     50.       3.\n",
      "    4.3944  86.    ]\n",
      " [ 40.       2.      26.5     93.     236.     147.      37.       7.\n",
      "    5.5607  92.    ]\n",
      " [ 58.       1.      25.7     99.     157.      91.6     49.       3.\n",
      "    4.4067  93.    ]\n",
      " [ 55.       2.      32.1    112.67   207.      92.4     25.       8.28\n",
      "    6.1048 111.    ]\n",
      " [ 48.       1.      29.5    131.     207.     132.2     47.       4.\n",
      "    4.9345 106.    ]\n",
      " [ 49.       2.      27.4     89.     177.     113.      37.       5.\n",
      "    4.9053  97.    ]\n",
      " [ 52.       1.      24.5     90.     198.     129.      29.       7.\n",
      "    5.2983  86.    ]\n",
      " [ 35.       1.      20.4     65.     187.     105.6     67.       2.79\n",
      "    4.2767  78.    ]\n",
      " [ 41.       2.      32.     109.     251.     170.6     49.       5.\n",
      "    5.0562 103.    ]\n",
      " [ 38.       1.      32.6     77.     168.     100.6     47.       4.\n",
      "    4.625   96.    ]\n",
      " [ 34.       1.      33.      73.     178.     114.6     51.       3.49\n",
      "    4.1271  92.    ]\n",
      " [ 50.       2.      23.7     92.     166.      97.      52.       3.\n",
      "    4.4427  93.    ]\n",
      " [ 69.       1.      29.6    122.     231.     128.4     56.       4.\n",
      "    5.451   86.    ]\n",
      " [ 46.       2.      42.2     99.     211.     137.      44.       5.\n",
      "    5.0106  99.    ]\n",
      " [ 57.       1.      24.5     93.     186.      96.6     71.       3.\n",
      "    4.5218  91.    ]\n",
      " [ 75.       1.      31.2    117.67   229.     138.8     29.       7.9\n",
      "    5.7236 106.    ]\n",
      " [ 49.       1.      22.7     65.33   168.      96.2     62.       2.71\n",
      "    3.8918  60.    ]\n",
      " [ 71.       2.      27.      93.33   269.     190.2     41.       6.56\n",
      "    5.2417  93.    ]\n",
      " [ 42.       2.      30.6    101.     269.     172.2     50.       5.\n",
      "    5.4553 106.    ]\n",
      " [ 68.       1.      32.8    105.67   205.     116.4     40.       5.13\n",
      "    5.4931 117.    ]\n",
      " [ 47.       2.      25.3     98.     173.     105.6     44.       4.\n",
      "    4.7622 108.    ]\n",
      " [ 72.       2.      30.5     93.     156.      93.6     41.       4.\n",
      "    4.6728  85.    ]\n",
      " [ 67.       2.      28.3     93.     204.     132.2     49.       4.\n",
      "    4.7362  92.    ]\n",
      " [ 53.       2.      27.7     95.     190.     101.8     41.       5.\n",
      "    5.4638 101.    ]\n",
      " [ 44.       2.      26.6     99.     205.     109.      43.       5.\n",
      "    5.5797 111.    ]\n",
      " [ 68.       2.      24.8    101.     221.     151.4     60.       4.\n",
      "    3.8712  87.    ]\n",
      " [ 68.       2.      23.5    101.     162.      85.4     59.       3.\n",
      "    4.4773  91.    ]\n",
      " [ 38.       2.      26.8    105.     181.     119.2     37.       5.\n",
      "    4.8203  91.    ]\n",
      " [ 33.       2.      25.4    102.     206.     141.      39.       5.\n",
      "    4.8675 105.    ]\n",
      " [ 22.       1.      18.6     97.     114.      57.6     46.       2.\n",
      "    3.9512  83.    ]\n",
      " [ 64.       2.      27.3    109.     186.     107.6     38.       5.\n",
      "    5.3083  99.    ]\n",
      " [ 39.       1.      22.9     77.     204.     143.2     46.       4.\n",
      "    4.3041  74.    ]\n",
      " [ 67.       2.      24.      83.     143.      77.2     49.       3.\n",
      "    4.4308  94.    ]\n",
      " [ 37.       2.      26.8     79.     157.      98.      28.       6.\n",
      "    5.0434  96.    ]\n",
      " [ 63.       1.      26.      85.67   155.      78.2     46.       3.37\n",
      "    5.037   97.    ]\n",
      " [ 46.       1.      24.9    115.     198.     129.6     54.       4.\n",
      "    4.2767 103.    ]\n",
      " [ 67.       2.      25.     111.67   146.      93.4     33.       4.42\n",
      "    4.585  103.    ]\n",
      " [ 52.       2.      24.3     86.     197.     133.6     44.       5.\n",
      "    4.5747  91.    ]\n",
      " [ 37.       2.      23.6     94.     205.     138.8     53.       4.\n",
      "    4.1897 107.    ]\n",
      " [ 60.       2.      32.1     83.     179.     119.4     42.       4.\n",
      "    4.4773  94.    ]\n",
      " [ 26.       2.      30.3     89.     218.     152.2     31.       7.\n",
      "    5.1591  82.    ]\n",
      " [ 51.       1.      23.5    101.     195.     121.      51.       4.\n",
      "    4.7449  94.    ]\n",
      " [ 40.       1.      30.7     99.     177.      85.4     50.       4.\n",
      "    5.3375  85.    ]\n",
      " [ 62.       1.      28.9     87.33   206.     127.2     33.       6.24\n",
      "    5.4337  99.    ]]\n"
     ]
    }
   ],
   "source": [
    "print(test_x)\n",
    "y_pred = le.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient [  0.17315432 -27.97960586   5.71004799   1.16949462  -1.04467924\n",
      "   0.61411045   0.24743382   7.62370087  64.9257693    0.29280766]\n",
      "intercept -317.9914987105119\n"
     ]
    }
   ],
   "source": [
    "print(\"coefficient\", le.coef_)\n",
    "print(\"intercept\", le.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>76.540331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128.0</td>\n",
       "      <td>170.261870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125.0</td>\n",
       "      <td>107.511257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.0</td>\n",
       "      <td>226.204220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.0</td>\n",
       "      <td>86.568073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>110.0</td>\n",
       "      <td>162.229438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>137.0</td>\n",
       "      <td>193.383433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>154.0</td>\n",
       "      <td>164.463894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>99.0</td>\n",
       "      <td>233.866755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>225.0</td>\n",
       "      <td>232.340062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual     Predict\n",
       "0     75.0   76.540331\n",
       "1    128.0  170.261870\n",
       "2    125.0  107.511257\n",
       "3    332.0  226.204220\n",
       "4     37.0   86.568073\n",
       "..     ...         ...\n",
       "84   110.0  162.229438\n",
       "85   137.0  193.383433\n",
       "86   154.0  164.463894\n",
       "87    99.0  233.866755\n",
       "88   225.0  232.340062\n",
       "\n",
       "[89 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({\"Actual\": test_y, \"Predict\": y_pred})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([198.13284446])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.predict(np.array([[60, 2, 28.2, 112.0, 185, 113.8, 42.0, 4.0, 4.9836, 93]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfb725626286d8c8fc5334ffe77697f720dc23e64d3046271825a5556b528e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
